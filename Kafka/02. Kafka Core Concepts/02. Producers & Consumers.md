# 02. Producers & Consumers

## Kafka Producer

### What is a Producer?

A **producer** is an application that sends (publishes) messages to Kafka topics.

```
Producer App → Kafka Topic → Stored in Partition
```

---

## Producer Workflow

```
┌──────────────┐
│   Producer   │
└──────┬───────┘
       │ 1. Create message
       ↓
┌──────────────────┐
│   Serializer     │ 2. Convert to bytes
└──────┬───────────┘
       │
       ↓
┌──────────────────┐
│   Partitioner    │ 3. Choose partition
└──────┬───────────┘
       │
       ↓
┌──────────────────┐
│   Buffer         │ 4. Batch messages
└──────┬───────────┘
       │
       ↓
┌──────────────────┐
│   Network        │ 5. Send to broker
└──────┬───────────┘
       │
       ↓
┌──────────────────┐
│   Kafka Broker   │ 6. Store & acknowledge
└──────────────────┘
```

---

## Producing Messages

### Simple Producer (Node.js)

```javascript
const { Kafka } = require('kafkajs');

const kafka = new Kafka({
  clientId: 'my-app',
  brokers: ['localhost:9092']
});

const producer = kafka.producer();

await producer.connect();

// Send message
await producer.send({
  topic: 'orders',
  messages: [
    { value: 'Order #123' }
  ]
});

await producer.disconnect();
```

### Producer with Key

```javascript
await producer.send({
  topic: 'orders',
  messages: [
    {
      key: 'user123',        // Messages with same key → same partition
      value: 'Order data'
    }
  ]
});
```

### Batch Messages

```javascript
await producer.send({
  topic: 'orders',
  messages: [
    { key: 'user1', value: 'Order 1' },
    { key: 'user2', value: 'Order 2' },
    { key: 'user3', value: 'Order 3' }
  ]
});
```

---

## Producer Configuration

### Key Configurations

```javascript
const producer = kafka.producer({
  // Acknowledgment level
  acks: 1,              // 0, 1, or 'all'
  
  // Compression
  compression: 'gzip',  // 'none', 'gzip', 'snappy', 'lz4'
  
  // Batching
  batch: {
    size: 16384,        // Batch size in bytes
    lingerMs: 10        // Wait time before sending
  },
  
  // Retries
  retry: {
    retries: 5,
    initialRetryTime: 100
  }
});
```

### Acknowledgment Modes (acks)

| Mode | Description | Durability | Performance |
|------|-------------|------------|-------------|
| **0** | No acknowledgment | Lowest | Fastest |
| **1** | Leader acknowledges | Medium | Medium |
| **all** | All replicas acknowledge | Highest | Slowest |

**Example:**

```javascript
// Fire and forget (fast, risky)
acks: 0

// Leader only (balanced)
acks: 1

// All replicas (safe, slow)
acks: 'all'
```

---

## Partitioner

### How Messages are Partitioned

```
With Key:
  partition = hash(key) % num_partitions
  
Without Key:
  Round-robin across partitions
```

### Example

```javascript
// All messages with same key go to same partition
await producer.send({
  topic: 'user-events',
  messages: [
    { key: 'user123', value: 'login' },     // → Partition 0
    { key: 'user123', value: 'view_page' }, // → Partition 0
    { key: 'user456', value: 'login' }      // → Partition 2
  ]
});
```

**Use case**: Maintain order for same user's events

---

## Message Format

### Basic Message

```javascript
{
  key: 'optional_key',
  value: 'message_payload',
  partition: 0,              // Optional: specify partition
  headers: {                 // Optional: metadata
    'correlation-id': '12345'
  },
  timestamp: Date.now()      // Optional: custom timestamp
}
```

---

## Kafka Consumer

### What is a Consumer?

A **consumer** is an application that reads (subscribes to) messages from Kafka topics.

```
Kafka Topic → Consumer App → Process Message
```

---

## Consumer Workflow

```
┌──────────────────┐
│   Kafka Broker   │
└──────┬───────────┘
       │ 1. Fetch messages
       ↓
┌──────────────────┐
│   Consumer       │ 2. Receive batch
└──────┬───────────┘
       │
       ↓
┌──────────────────┐
│   Deserializer   │ 3. Convert from bytes
└──────┬───────────┘
       │
       ↓
┌──────────────────┐
│   Process        │ 4. Business logic
└──────┬───────────┘
       │
       ↓
┌──────────────────┐
│   Commit Offset  │ 5. Mark as processed
└──────────────────┘
```

---

## Consuming Messages

### Simple Consumer (Node.js)

```javascript
const consumer = kafka.consumer({ groupId: 'my-group' });

await consumer.connect();
await consumer.subscribe({ topic: 'orders' });

await consumer.run({
  eachMessage: async ({ topic, partition, message }) => {
    console.log({
      offset: message.offset,
      key: message.key?.toString(),
      value: message.value.toString()
    });
  }
});
```

### Consumer from Beginning

```javascript
await consumer.subscribe({ 
  topic: 'orders',
  fromBeginning: true  // Read all historical messages
});
```

### Multiple Topics

```javascript
await consumer.subscribe({ 
  topics: ['orders', 'users', 'products']
});
```

### Topic Pattern

```javascript
await consumer.subscribe({ 
  topics: /^user\..*/  // Subscribe to user.login, user.logout, etc.
});
```

---

## Consumer Configuration

### Key Configurations

```javascript
const consumer = kafka.consumer({
  groupId: 'my-consumer-group',
  
  // Auto commit offset
  autoCommit: true,
  autoCommitInterval: 5000,  // 5 seconds
  
  // Session timeout
  sessionTimeout: 30000,
  heartbeatInterval: 3000,
  
  // Max messages per fetch
  maxBytesPerPartition: 1048576,
  
  // Offset reset strategy
  fromBeginning: false
});
```

---

## Offset Management

### What is Offset?

Offset is the position of a message within a partition.

```
Partition 0:
┌────────┬────────┬────────┬────────┐
│ Offset │   0    │   1    │   2    │
├────────┼────────┼────────┼────────┤
│  Msg   │   A    │   B    │   C    │
└────────┴────────┴────────┴────────┘
                            ↑
                    Consumer read up to here
```

### Auto Commit (Default)

```javascript
const consumer = kafka.consumer({
  groupId: 'my-group',
  autoCommit: true,
  autoCommitInterval: 5000  // Commit every 5 seconds
});
```

**Pros**: Simple, automatic
**Cons**: May lose messages on crash

### Manual Commit

```javascript
const consumer = kafka.consumer({
  groupId: 'my-group',
  autoCommit: false
});

await consumer.run({
  eachMessage: async ({ topic, partition, message }) => {
    // Process message
    await processMessage(message);
    
    // Manually commit offset
    await consumer.commitOffsets([
      {
        topic,
        partition,
        offset: (parseInt(message.offset) + 1).toString()
      }
    ]);
  }
});
```

**Pros**: Exactly-once processing
**Cons**: More complex, slower

---

## Consumer Patterns

### Pattern 1: Single Consumer

```
Topic (3 partitions):
P0: [msg1] [msg2] [msg3]
P1: [msg4] [msg5] [msg6]
P2: [msg7] [msg8] [msg9]
     ↓      ↓      ↓
    Consumer reads all partitions
```

### Pattern 2: Multiple Consumers (Same Group)

```
Topic (3 partitions):
P0: [msg1] [msg2]  →  Consumer 1
P1: [msg3] [msg4]  →  Consumer 2
P2: [msg5] [msg6]  →  Consumer 3

Load balanced across consumers
```

### Pattern 3: Multiple Consumer Groups

```
Topic (2 partitions):
P0: [msg1] [msg2]
P1: [msg3] [msg4]
     ↓      ↓
  Group A (Email service)
     ↓      ↓
  Group B (Analytics service)
  
Same data consumed by both groups independently
```

---

## Rebalancing

### What is Rebalancing?

Reassignment of partitions to consumers when:
- Consumer joins the group
- Consumer leaves the group
- Consumer crashes
- New partitions added

### Example

**Before:**
```
Consumer 1: P0, P1
Consumer 2: P2, P3
```

**Consumer 3 joins:**
```
Consumer 1: P0
Consumer 2: P1, P2
Consumer 3: P3
```

**During rebalancing**: Consumers pause and resume after reassignment

---

## Error Handling

### Retry Pattern

```javascript
await consumer.run({
  eachMessage: async ({ topic, partition, message }) => {
    let retries = 0;
    const maxRetries = 3;
    
    while (retries < maxRetries) {
      try {
        await processMessage(message);
        break;  // Success
      } catch (error) {
        retries++;
        if (retries >= maxRetries) {
          // Send to dead letter queue
          await sendToDLQ(message, error);
        }
        await sleep(1000 * retries);  // Exponential backoff
      }
    }
  }
});
```

---

## Performance Optimization

### Producer Optimization

```javascript
const producer = kafka.producer({
  compression: 'gzip',      // Reduce network usage
  batch: {
    size: 16384,            // Larger batches
    lingerMs: 10            // Wait to batch more messages
  },
  idempotence: true         // Prevent duplicates
});
```

### Consumer Optimization

```javascript
const consumer = kafka.consumer({
  groupId: 'my-group',
  maxBytesPerPartition: 1048576,  // Fetch more data
  sessionTimeout: 30000,
  heartbeatInterval: 3000,
  maxWaitTimeInMs: 100            // Reduce latency
});
```

---

## Best Practices

### Producer

✅ **Use message keys** for ordering
✅ **Enable compression** to save bandwidth
✅ **Batch messages** for better throughput
✅ **Set appropriate acks** (1 for balanced, all for critical)
✅ **Handle errors** with retries

### Consumer

✅ **Use consumer groups** for scalability
✅ **Commit offsets carefully** (manual for critical data)
✅ **Handle rebalancing** gracefully
✅ **Process idempotently** (handle duplicates)
✅ **Monitor lag** to ensure keeping up

---

## Summary

**Producer:**
- Sends messages to topics
- Can specify key for partitioning
- Configurable acks (0, 1, all)
- Batching & compression for performance

**Consumer:**
- Reads messages from topics
- Part of consumer group
- Tracks offset (position)
- Auto or manual commit

**Flow:**
```
Producer → [Serialize] → [Partition] → Broker
Broker → [Fetch] → [Deserialize] → Consumer
```

---

## Interview Questions & Answers

### Q1: What is a Kafka producer?
**A:** A producer is an application that publishes (sends) messages to Kafka topics. It serializes data, determines the partition, batches messages, and sends them to the broker.

### Q2: What is a Kafka consumer?
**A:** A consumer is an application that subscribes to and reads messages from Kafka topics. It fetches messages, deserializes them, processes them, and commits offsets to track progress.

### Q3: What are the different acknowledgment modes (acks) in Kafka?
**A:**
- **acks=0**: No acknowledgment (fire-and-forget, fastest, may lose data)
- **acks=1**: Leader broker acknowledges (balanced)
- **acks=all**: All in-sync replicas acknowledge (safest, slowest)

### Q4: How does Kafka decide which partition a message goes to?
**A:**
- **With key**: `partition = hash(key) % num_partitions` (deterministic)
- **Without key**: Round-robin or sticky partitioner (load balanced)
- **Custom partitioner**: Implement custom logic

### Q5: What is the purpose of a message key?
**A:** Message key ensures:
- Messages with same key go to same partition
- Maintains ordering for related messages
- Example: All events for userId='123' in same partition

### Q6: What is offset in Kafka?
**A:** Offset is a unique sequential number assigned to each message within a partition. It starts at 0 and increments for each message. Consumers use offsets to track which messages they've processed.

### Q7: What is the difference between auto-commit and manual commit?
**A:**
- **Auto-commit**: Kafka automatically commits offsets at intervals (simple, may lose messages)
- **Manual commit**: Application explicitly commits after processing (safer, more control, exactly-once)

### Q8: What happens if a consumer in a group crashes?
**A:** Kafka triggers a **rebalance**:
1. Remaining consumers pause
2. Partitions reassigned among active consumers
3. Consumers resume with new assignments
4. Failed consumer's partitions are redistributed

### Q9: Can multiple consumers in the same group read from the same partition?
**A:** No. Each partition is assigned to only one consumer within a consumer group. However, multiple consumer groups can read from the same partition independently.

### Q10: What is consumer lag?
**A:** Consumer lag is the difference between the last produced message offset and the consumer's current offset. It indicates how far behind the consumer is.

```
Lag = Latest Offset - Consumer Offset
Lag = 1000 - 950 = 50 messages behind
```

### Q11: How do you ensure message ordering in Kafka?
**A:**
- Use a **message key** to ensure related messages go to same partition
- Ordering guaranteed within a partition
- Not guaranteed across partitions
- Use single partition if global ordering needed (limits parallelism)

### Q12: What is idempotent producer?
**A:** An idempotent producer prevents duplicate messages even if producer retries. Enable with:
```javascript
idempotence: true
```
Kafka assigns unique ID to each message to detect duplicates.

### Q13: What is compression in Kafka and why use it?
**A:** Compression reduces message size before sending, saving:
- Network bandwidth
- Disk storage
- I/O operations

Types: `gzip`, `snappy`, `lz4`, `zstd`

### Q14: What is batching in Kafka producer?
**A:** Batching groups multiple messages before sending to broker:
- Improves throughput
- Reduces network overhead
- Configure with `batch.size` and `linger.ms`

### Q15: How does a consumer group achieve scalability?
**A:** Consumer group distributes partitions among consumers:
- Each partition assigned to one consumer
- Add more consumers to process more partitions in parallel
- Maximum consumers = number of partitions
- Example: 10 partitions → up to 10 consumers for parallel processing

**Next:** Consumer Groups & Offsets!