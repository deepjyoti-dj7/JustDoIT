# 03. Consumer Groups & Offsets

## Consumer Groups

### What is a Consumer Group?

A **consumer group** is a set of consumers that work together to consume messages from topics.

**Key principle**: Each partition is consumed by only ONE consumer within a group.

```
Topic: orders (3 partitions)

Consumer Group "service-a"
┌─────────────────────────────────┐
│  Consumer 1 ← Partition 0       │
│  Consumer 2 ← Partition 1       │
│  Consumer 3 ← Partition 2       │
└─────────────────────────────────┘

Consumer Group "service-b" (independent)
┌─────────────────────────────────┐
│  Consumer 1 ← Partition 0, 1, 2 │
└─────────────────────────────────┘
```

---

## Why Consumer Groups?

### 1. Scalability (Parallel Processing)

```
Without Consumer Group:
1 Consumer reads all partitions (slow)

With Consumer Group:
3 Consumers read 3 partitions in parallel (3x faster)
```

### 2. Fault Tolerance

```
If Consumer 2 crashes:
Partition 1 reassigned to Consumer 1 or 3
No messages lost
```

### 3. Multiple Independent Consumers

```
Same Topic:
  → Group A (Email Service)
  → Group B (Analytics Service)
  → Group C (Logging Service)
  
Each group processes ALL messages independently
```

---

## Consumer Group Patterns

### Pattern 1: More Consumers than Partitions

```
Topic (2 partitions):
P0, P1

Consumer Group (3 consumers):
Consumer 1 → P0
Consumer 2 → P1
Consumer 3 → Idle (no partition assigned)

❌ Consumer 3 is wasted
```

**Rule**: Max useful consumers = number of partitions

### Pattern 2: Equal Consumers and Partitions

```
Topic (3 partitions):
P0, P1, P2

Consumer Group (3 consumers):
Consumer 1 → P0
Consumer 2 → P1
Consumer 3 → P2

✅ Perfect load balancing
```

### Pattern 3: Fewer Consumers than Partitions

```
Topic (6 partitions):
P0, P1, P2, P3, P4, P5

Consumer Group (2 consumers):
Consumer 1 → P0, P1, P2
Consumer 2 → P3, P4, P5

✅ Still works, each consumer handles multiple partitions
```

---

## Creating Consumer Groups

### Node.js (KafkaJS)

```javascript
const consumer = kafka.consumer({ 
  groupId: 'email-service'  // Consumer group ID
});

await consumer.connect();
await consumer.subscribe({ topic: 'orders' });

await consumer.run({
  eachMessage: async ({ topic, partition, message }) => {
    console.log(`Group: email-service`);
    console.log(`Partition: ${partition}`);
    console.log(`Message: ${message.value.toString()}`);
  }
});
```

### Multiple Groups (Same Topic)

```javascript
// Group 1: Email Service
const emailConsumer = kafka.consumer({ groupId: 'email-service' });
await emailConsumer.subscribe({ topic: 'orders' });

// Group 2: Analytics Service
const analyticsConsumer = kafka.consumer({ groupId: 'analytics-service' });
await analyticsConsumer.subscribe({ topic: 'orders' });

// Both receive ALL messages independently
```

---

## Partition Assignment

### How Partitions are Assigned

Kafka automatically assigns partitions to consumers using strategies:

#### 1. Range Assignor (Default)

```
Topic (4 partitions): P0, P1, P2, P3
Consumer Group (2 consumers):

Consumer 1: P0, P1
Consumer 2: P2, P3
```

#### 2. Round-Robin Assignor

```
Topics: orders (P0, P1), users (P0, P1)
Consumer Group (2 consumers):

Consumer 1: orders-P0, users-P1
Consumer 2: orders-P1, users-P0

Better distribution across topics
```

#### 3. Sticky Assignor

Minimizes partition movement during rebalance.

```javascript
const consumer = kafka.consumer({
  groupId: 'my-group',
  partitionAssigners: [
    'RoundRobinAssigner',
    'StickyAssigner'
  ]
});
```

---

## Consumer Rebalancing

### What is Rebalancing?

Reassignment of partitions when:
- Consumer joins
- Consumer leaves/crashes
- Consumer exceeds session timeout
- New partitions added

### Rebalance Example

**Before:**
```
Consumer 1: P0, P1
Consumer 2: P2, P3
```

**Consumer 3 joins:**
```
[Rebalancing...]

Consumer 1: P0
Consumer 2: P1, P2
Consumer 3: P3
```

**Consumer 2 crashes:**
```
[Rebalancing...]

Consumer 1: P0, P1, P2
Consumer 3: P3
```

### Rebalance Impact

❌ **During rebalancing:**
- All consumers stop processing
- Partitions reassigned
- Resume after reassignment

⏱️ **Typical duration**: Few seconds

### Minimize Rebalancing

```javascript
const consumer = kafka.consumer({
  groupId: 'my-group',
  sessionTimeout: 30000,      // Increase timeout
  heartbeatInterval: 3000,    // Send heartbeats frequently
  maxPollInterval: 300000     // Max time between polls
});
```

---

## Offsets

### What is an Offset?

An **offset** is the position of a message within a partition.

```
Partition 0:
┌──────┬──────┬──────┬──────┬──────┐
│Offset│  0   │  1   │  2   │  3   │
├──────┼──────┼──────┼──────┼──────┤
│ Msg  │  A   │  B   │  C   │  D   │
└──────┴──────┴──────┴──────┴──────┘
                        ↑
              Consumer at offset 2
```

### Offset Storage

Kafka stores consumer offsets in internal topic:
```
__consumer_offsets
```

**Stored data:**
```json
{
  "group": "my-group",
  "topic": "orders",
  "partition": 0,
  "offset": 150,
  "timestamp": 1234567890
}
```

---

## Offset Commit Strategies

### 1. Auto Commit (Default)

```javascript
const consumer = kafka.consumer({
  groupId: 'my-group',
  autoCommit: true,
  autoCommitInterval: 5000  // Every 5 seconds
});

await consumer.run({
  eachMessage: async ({ message }) => {
    await processMessage(message);
    // Offset committed automatically
  }
});
```

**Pros:**
- ✅ Simple, automatic

**Cons:**
- ❌ May lose messages on crash
- ❌ May process duplicates on restart

### 2. Manual Commit (After Each Message)

```javascript
const consumer = kafka.consumer({
  groupId: 'my-group',
  autoCommit: false
});

await consumer.run({
  eachMessage: async ({ topic, partition, message }) => {
    await processMessage(message);
    
    // Commit after successful processing
    await consumer.commitOffsets([
      {
        topic,
        partition,
        offset: (parseInt(message.offset) + 1).toString()
      }
    ]);
  }
});
```

**Pros:**
- ✅ No message loss
- ✅ Exactly-once semantics

**Cons:**
- ❌ Slower (network call per message)

### 3. Manual Batch Commit

```javascript
const consumer = kafka.consumer({
  groupId: 'my-group',
  autoCommit: false
});

let messageCount = 0;
const BATCH_SIZE = 100;

await consumer.run({
  eachMessage: async ({ topic, partition, message }) => {
    await processMessage(message);
    messageCount++;
    
    // Commit every 100 messages
    if (messageCount % BATCH_SIZE === 0) {
      await consumer.commitOffsets([
        {
          topic,
          partition,
          offset: (parseInt(message.offset) + 1).toString()
        }
      ]);
    }
  }
});
```

**Pros:**
- ✅ Better performance than per-message commit
- ✅ Less network overhead

**Cons:**
- ❌ May reprocess up to BATCH_SIZE messages on crash

---

## Offset Reset Behavior

### When Starting New Consumer Group

```javascript
const consumer = kafka.consumer({
  groupId: 'new-group',
  fromBeginning: true  // Start from offset 0
});
```

**Options:**
- `fromBeginning: true` → Start at offset 0 (earliest)
- `fromBeginning: false` → Start at latest offset (default)

### Auto Offset Reset

What to do when offset is invalid:

```javascript
const consumer = kafka.consumer({
  groupId: 'my-group',
  autoOffsetReset: 'earliest'  // or 'latest'
});
```

**Cases:**
- Offset out of range (too old, deleted by retention)
- No committed offset for partition

---

## Managing Offsets

### View Consumer Group Offsets

```bash
kafka-consumer-groups.sh --describe \
  --group my-group \
  --bootstrap-server localhost:9092
```

**Output:**
```
GROUP     TOPIC    PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG
my-group  orders   0          100             150             50
my-group  orders   1          200             200             0
my-group  orders   2          150             180             30
```

### Reset Offsets

**To earliest:**
```bash
kafka-consumer-groups.sh --reset-offsets \
  --group my-group \
  --topic orders \
  --to-earliest \
  --execute
```

**To specific offset:**
```bash
kafka-consumer-groups.sh --reset-offsets \
  --group my-group \
  --topic orders:0 \
  --to-offset 100 \
  --execute
```

**To timestamp:**
```bash
kafka-consumer-groups.sh --reset-offsets \
  --group my-group \
  --topic orders \
  --to-datetime 2024-01-01T00:00:00.000 \
  --execute
```

---

## Consumer Lag

### What is Consumer Lag?

Difference between latest message and consumer's position:

```
Lag = Log End Offset - Current Offset
Lag = 1000 - 950 = 50 messages behind
```

### Monitoring Lag

```javascript
const { HEARTBEAT } = consumer.events;

consumer.on(HEARTBEAT, ({ groupId, payload }) => {
  console.log('Consumer lag:', payload.lag);
});
```

### Handling High Lag

**Solutions:**
1. Add more consumers (up to partition count)
2. Optimize processing speed
3. Increase fetch size
4. Process in batches

---

## Best Practices

### Consumer Groups

✅ **Use meaningful group IDs**: `email-service`, `analytics-pipeline`
✅ **One group per logical application**
✅ **Max consumers ≤ partitions**: Extra consumers are idle
✅ **Monitor rebalances**: Frequent rebalances indicate issues

### Offsets

✅ **Manual commit for critical data**: Ensures no message loss
✅ **Auto commit for high throughput**: When duplicates acceptable
✅ **Batch commits**: Balance between safety and performance
✅ **Monitor lag**: Set alerts for high lag
✅ **Idempotent processing**: Handle duplicate messages gracefully

---

## Summary

**Consumer Group:**
- Set of consumers working together
- Each partition assigned to one consumer
- Enables parallel processing
- Automatic rebalancing on changes

**Offset:**
- Position in partition
- Stored in `__consumer_offsets` topic
- Committed automatically or manually
- Enables resuming from last position

**Key Concepts:**
```
Consumers ≤ Partitions (for efficiency)
Lag = Latest Offset - Consumer Offset
Rebalancing = Partition reassignment
```

---

## Interview Questions & Answers

### Q1: What is a consumer group in Kafka?
**A:** A consumer group is a set of consumers that work together to consume messages from topics. Each partition is assigned to only one consumer within the group, enabling parallel processing and load balancing.

### Q2: Can multiple consumers in the same group read from the same partition?
**A:** No. Each partition is assigned to exactly one consumer within a consumer group. However, multiple consumer groups can read from the same partition independently.

### Q3: What is the maximum number of useful consumers in a consumer group?
**A:** The maximum useful consumers equals the number of partitions. Extra consumers beyond this will be idle with no partitions assigned.

Example: 5 partitions → maximum 5 useful consumers

### Q4: What happens when a consumer in a group crashes?
**A:** Kafka triggers a **rebalance**:
1. Detects consumer failure (via heartbeat/session timeout)
2. Remaining consumers pause
3. Partitions redistributed among active consumers
4. Consumers resume with new assignments
5. Failed consumer's partitions continue being processed

### Q5: What is consumer rebalancing?
**A:** Rebalancing is the reassignment of partitions to consumers when:
- Consumer joins/leaves the group
- Consumer crashes or exceeds timeout
- New partitions added to topic

During rebalancing, all consumers pause briefly while partitions are reassigned.

### Q6: What is an offset in Kafka?
**A:** An offset is a unique sequential number identifying each message's position within a partition. It starts at 0 and increments for each new message. Consumers use offsets to track their progress.

### Q7: Where are consumer offsets stored?
**A:** Consumer offsets are stored in an internal Kafka topic called `__consumer_offsets`. This allows consumers to resume from their last position after restart.

### Q8: What is the difference between auto-commit and manual commit?
**A:**
- **Auto-commit**: Kafka automatically commits offsets at intervals (simple, may lose messages on crash)
- **Manual commit**: Application explicitly commits after processing (safer, exactly-once, more control)

### Q9: What is consumer lag?
**A:** Consumer lag is the difference between the latest produced message offset and the consumer's current offset:
```
Lag = Log End Offset - Consumer Offset
```
High lag means consumer is falling behind.

### Q10: How do you reduce consumer lag?
**A:**
1. Add more consumers (up to partition count)
2. Optimize message processing speed
3. Increase fetch size for batch processing
4. Process messages in parallel (within consumer)
5. Scale up consumer resources (CPU, memory)

### Q11: What happens when you reset consumer group offset?
**A:** Resetting offset changes where the consumer starts reading:
- **To earliest**: Reprocess all messages from beginning
- **To latest**: Skip to newest messages
- **To specific offset**: Start from exact position
- **To timestamp**: Start from specific time

### Q12: Can different consumer groups read the same topic?
**A:** Yes. Multiple consumer groups can subscribe to the same topic and each will receive all messages independently. This enables multiple applications to process the same data stream.

Example:
```
Topic: orders
  → email-service group (sends emails)
  → analytics-service group (analyzes data)
  → billing-service group (processes payments)
```

### Q13: What is `fromBeginning` option in consumer?
**A:** `fromBeginning: true` makes a new consumer group start reading from offset 0 (earliest message). Default is `false` (start from latest). Only applies when there's no committed offset for the group.

### Q14: What is the `__consumer_offsets` topic?
**A:** It's an internal Kafka topic that stores:
- Consumer group offsets
- Group metadata
- Partition assignments

Kafka uses this to track consumer progress and enable resuming after restart.

### Q15: How do you handle duplicate message processing?
**A:**
1. **Idempotent processing**: Design logic to handle duplicates safely
2. **Deduplication**: Track processed message IDs in database
3. **Exactly-once**: Use manual offset commit only after successful processing
4. **Idempotent producer**: Enable `idempotence: true` on producer

**Next:** Replication & Leaders!