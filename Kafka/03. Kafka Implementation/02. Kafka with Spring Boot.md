# 02. Kafka with Spring Boot

## What is Spring Kafka?

**Spring Kafka** is a Spring Framework module that provides integration with Apache Kafka.

**Features:**
✅ High-level abstraction over Kafka clients
✅ Auto-configuration with Spring Boot
✅ Template-based message sending
✅ Annotation-based message listeners
✅ Error handling and retry support
✅ Transaction management

---

## Setup

### Maven Dependency

```xml
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>
```

### Gradle Dependency

```gradle
implementation 'org.springframework.kafka:spring-kafka'
```

### application.properties

```properties
# Kafka Bootstrap Servers
spring.kafka.bootstrap-servers=localhost:9092

# Producer Configuration
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.acks=all
spring.kafka.producer.retries=3

# Consumer Configuration
spring.kafka.consumer.group-id=my-group
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.auto-offset-reset=earliest
```

### application.yml

```yaml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: all
    consumer:
      group-id: my-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      auto-offset-reset: earliest
```

---

## Producer

### Using KafkaTemplate

```java
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;

@Service
public class OrderProducer {

    private final KafkaTemplate<String, String> kafkaTemplate;

    public OrderProducer(KafkaTemplate<String, String> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }

    public void sendOrder(String orderId, String orderData) {
        kafkaTemplate.send("orders", orderId, orderData);
    }
}
```

### Send with Callback

```java
import org.springframework.kafka.support.SendResult;
import org.springframework.util.concurrent.ListenableFuture;
import org.springframework.util.concurrent.ListenableFutureCallback;

public void sendOrderWithCallback(String orderId, String orderData) {
    ListenableFuture<SendResult<String, String>> future = 
        kafkaTemplate.send("orders", orderId, orderData);
    
    future.addCallback(new ListenableFutureCallback<>() {
        @Override
        public void onSuccess(SendResult<String, String> result) {
            System.out.println("Sent message: " + orderData + 
                " with offset: " + result.getRecordMetadata().offset());
        }

        @Override
        public void onFailure(Throwable ex) {
            System.err.println("Failed to send message: " + ex.getMessage());
        }
    });
}
```

### Send to Specific Partition

```java
public void sendToPartition(String message) {
    kafkaTemplate.send("orders", 0, "key", message);  // Partition 0
}
```

### Send with Headers

```java
import org.springframework.kafka.support.KafkaHeaders;
import org.springframework.messaging.Message;
import org.springframework.messaging.support.MessageBuilder;

public void sendWithHeaders(String orderId, String orderData) {
    Message<String> message = MessageBuilder
        .withPayload(orderData)
        .setHeader(KafkaHeaders.TOPIC, "orders")
        .setHeader(KafkaHeaders.MESSAGE_KEY, orderId)
        .setHeader("correlation-id", "12345")
        .build();
    
    kafkaTemplate.send(message);
}
```

---

## Consumer

### Simple Consumer

```java
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Service;

@Service
public class OrderConsumer {

    @KafkaListener(topics = "orders", groupId = "order-group")
    public void consume(String message) {
        System.out.println("Received: " + message);
    }
}
```

### Consumer with Key and Value

```java
@KafkaListener(topics = "orders", groupId = "order-group")
public void consumeWithKey(
    @Header(KafkaHeaders.RECEIVED_MESSAGE_KEY) String key,
    @Payload String value) {
    
    System.out.println("Key: " + key);
    System.out.println("Value: " + value);
}
```

### Consumer with Metadata

```java
import org.apache.kafka.clients.consumer.ConsumerRecord;

@KafkaListener(topics = "orders", groupId = "order-group")
public void consumeWithMetadata(ConsumerRecord<String, String> record) {
    System.out.println("Topic: " + record.topic());
    System.out.println("Partition: " + record.partition());
    System.out.println("Offset: " + record.offset());
    System.out.println("Key: " + record.key());
    System.out.println("Value: " + record.value());
}
```

### Multiple Topics

```java
@KafkaListener(topics = {"orders", "users", "products"}, groupId = "multi-topic-group")
public void consumeMultipleTopics(String message) {
    System.out.println("Received: " + message);
}
```

### Topic Pattern

```java
@KafkaListener(topicPattern = "logs\\..*", groupId = "log-group")
public void consumeLogTopics(String message) {
    System.out.println("Log: " + message);
}
```

---

## JSON Serialization

### Configuration

```properties
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.trusted.packages=*
```

### Order Model

```java
public class Order {
    private String orderId;
    private String userId;
    private double amount;
    
    // Constructors, getters, setters
    public Order() {}
    
    public Order(String orderId, String userId, double amount) {
        this.orderId = orderId;
        this.userId = userId;
        this.amount = amount;
    }
    
    // Getters and setters
}
```

### Producer with JSON

```java
@Service
public class OrderProducer {

    private final KafkaTemplate<String, Order> kafkaTemplate;

    public OrderProducer(KafkaTemplate<String, Order> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }

    public void sendOrder(Order order) {
        kafkaTemplate.send("orders", order.getUserId(), order);
    }
}
```

### Consumer with JSON

```java
@Service
public class OrderConsumer {

    @KafkaListener(topics = "orders", groupId = "order-group")
    public void consume(Order order) {
        System.out.println("Order ID: " + order.getOrderId());
        System.out.println("User ID: " + order.getUserId());
        System.out.println("Amount: " + order.getAmount());
    }
}
```

---

## Manual Offset Commit

### Configuration

```properties
spring.kafka.consumer.enable-auto-commit=false
```

### Manual Commit

```java
import org.springframework.kafka.support.Acknowledgment;

@KafkaListener(topics = "orders", groupId = "order-group")
public void consumeManual(String message, Acknowledgment acknowledgment) {
    try {
        // Process message
        processMessage(message);
        
        // Manual commit
        acknowledgment.acknowledge();
    } catch (Exception e) {
        System.err.println("Failed to process: " + e.getMessage());
    }
}

private void processMessage(String message) {
    System.out.println("Processing: " + message);
}
```

---

## Error Handling

### Default Error Handler

```java
import org.springframework.kafka.listener.SeekToCurrentErrorHandler;
import org.springframework.kafka.support.converter.RecordMessageConverter;
import org.springframework.util.backoff.FixedBackOff;

@Bean
public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory() {
    ConcurrentKafkaListenerContainerFactory<String, String> factory =
        new ConcurrentKafkaListenerContainerFactory<>();
    factory.setConsumerFactory(consumerFactory());
    factory.setErrorHandler(new SeekToCurrentErrorHandler(new FixedBackOff(1000L, 3)));
    return factory;
}
```

### Custom Error Handler

```java
@Service
public class OrderConsumer {

    @KafkaListener(topics = "orders", groupId = "order-group")
    public void consume(String message) {
        try {
            processMessage(message);
        } catch (Exception e) {
            handleError(message, e);
        }
    }
    
    private void handleError(String message, Exception e) {
        System.err.println("Error processing: " + message);
        System.err.println("Error: " + e.getMessage());
        // Send to dead letter queue
    }
}
```

---

## Dead Letter Queue (DLQ)

### Configuration

```java
import org.springframework.kafka.listener.DeadLetterPublishingRecoverer;
import org.springframework.kafka.listener.SeekToCurrentErrorHandler;
import org.springframework.util.backoff.FixedBackOff;

@Bean
public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory(
        KafkaTemplate<String, String> kafkaTemplate) {
    
    ConcurrentKafkaListenerContainerFactory<String, String> factory =
        new ConcurrentKafkaListenerContainerFactory<>();
    factory.setConsumerFactory(consumerFactory());
    
    // Dead letter publisher
    DeadLetterPublishingRecoverer recoverer = 
        new DeadLetterPublishingRecoverer(kafkaTemplate);
    
    // Retry 3 times with 1 second delay, then send to DLQ
    factory.setErrorHandler(
        new SeekToCurrentErrorHandler(recoverer, new FixedBackOff(1000L, 3)));
    
    return factory;
}
```

### Consume from DLQ

```java
@KafkaListener(topics = "orders.DLT", groupId = "dlq-group")
public void consumeDLQ(String message) {
    System.out.println("Failed message from DLQ: " + message);
    // Handle failed messages
}
```

---

## Batch Listening

### Configuration

```properties
spring.kafka.listener.type=batch
spring.kafka.consumer.max-poll-records=100
```

### Batch Consumer

```java
import java.util.List;

@KafkaListener(topics = "orders", groupId = "batch-group")
public void consumeBatch(List<String> messages) {
    System.out.println("Received batch of " + messages.size() + " messages");
    
    for (String message : messages) {
        processMessage(message);
    }
}
```

### Batch with Metadata

```java
@KafkaListener(topics = "orders", groupId = "batch-group")
public void consumeBatchWithMetadata(List<ConsumerRecord<String, String>> records) {
    for (ConsumerRecord<String, String> record : records) {
        System.out.println("Offset: " + record.offset() + ", Value: " + record.value());
    }
}
```

---

## Complete Example

### Order.java

```java
public class Order {
    private String orderId;
    private String userId;
    private double amount;
    private String status;
    
    // Constructors
    public Order() {}
    
    public Order(String orderId, String userId, double amount) {
        this.orderId = orderId;
        this.userId = userId;
        this.amount = amount;
        this.status = "PENDING";
    }
    
    // Getters and Setters
    public String getOrderId() { return orderId; }
    public void setOrderId(String orderId) { this.orderId = orderId; }
    
    public String getUserId() { return userId; }
    public void setUserId(String userId) { this.userId = userId; }
    
    public double getAmount() { return amount; }
    public void setAmount(double amount) { this.amount = amount; }
    
    public String getStatus() { return status; }
    public void setStatus(String status) { this.status = status; }
}
```

### OrderService.java

```java
import org.springframework.stereotype.Service;

@Service
public class OrderService {
    
    private final OrderProducer orderProducer;
    
    public OrderService(OrderProducer orderProducer) {
        this.orderProducer = orderProducer;
    }
    
    public void createOrder(String userId, double amount) {
        String orderId = UUID.randomUUID().toString();
        Order order = new Order(orderId, userId, amount);
        
        orderProducer.sendOrder(order);
        System.out.println("Order created: " + orderId);
    }
}
```

### OrderProducer.java

```java
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Component;

@Component
public class OrderProducer {
    
    private final KafkaTemplate<String, Order> kafkaTemplate;
    
    public OrderProducer(KafkaTemplate<String, Order> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }
    
    public void sendOrder(Order order) {
        kafkaTemplate.send("orders", order.getUserId(), order);
    }
}
```

### OrderConsumer.java

```java
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Component;

@Component
public class OrderConsumer {
    
    @KafkaListener(topics = "orders", groupId = "order-processing-group")
    public void consume(Order order) {
        System.out.println("Processing order: " + order.getOrderId());
        System.out.println("User: " + order.getUserId());
        System.out.println("Amount: $" + order.getAmount());
        
        // Business logic
        processOrder(order);
    }
    
    private void processOrder(Order order) {
        // Validate
        // Check inventory
        // Process payment
        // Update database
        order.setStatus("COMPLETED");
    }
}
```

### OrderController.java

```java
import org.springframework.web.bind.annotation.*;

@RestController
@RequestMapping("/api/orders")
public class OrderController {
    
    private final OrderService orderService;
    
    public OrderController(OrderService orderService) {
        this.orderService = orderService;
    }
    
    @PostMapping
    public String createOrder(@RequestParam String userId, 
                             @RequestParam double amount) {
        orderService.createOrder(userId, amount);
        return "Order created successfully";
    }
}
```

---

## Best Practices

### Configuration

✅ Use environment-specific properties
✅ Enable idempotence for producers
✅ Set appropriate batch sizes
✅ Configure retries and timeouts

```properties
spring.kafka.producer.acks=all
spring.kafka.producer.enable.idempotence=true
spring.kafka.producer.max.in.flight.requests.per.connection=5
```

### Error Handling

✅ Implement retry logic
✅ Use dead letter queues
✅ Log errors with context
✅ Monitor consumer lag

### Performance

✅ Use batch processing for high throughput
✅ Enable compression
✅ Tune consumer fetch settings
✅ Use concurrent consumers

```properties
spring.kafka.producer.compression-type=gzip
spring.kafka.listener.concurrency=3
```

---

## Summary

**Spring Kafka:**
- High-level abstraction over Kafka
- Auto-configuration with Spring Boot
- Template and annotation-based

**Producer:**
```java
kafkaTemplate.send("topic", key, value);
```

**Consumer:**
```java
@KafkaListener(topics = "topic", groupId = "group")
public void consume(String message) {}
```

**Key Features:**
- JSON serialization
- Manual offset commit
- Error handling & DLQ
- Batch processing

---

## Interview Questions & Answers

### Q1: What is Spring Kafka?
**A:** Spring Kafka is a Spring Framework module that provides integration with Apache Kafka. It offers high-level abstractions like KafkaTemplate for producers and @KafkaListener for consumers, along with auto-configuration in Spring Boot.

### Q2: How do you send a message using KafkaTemplate?
**A:**
```java
@Autowired
private KafkaTemplate<String, String> kafkaTemplate;

public void sendMessage(String topic, String message) {
    kafkaTemplate.send(topic, message);
}
```

### Q3: How do you create a Kafka consumer in Spring Boot?
**A:**
```java
@Service
public class MyConsumer {
    @KafkaListener(topics = "my-topic", groupId = "my-group")
    public void consume(String message) {
        System.out.println("Received: " + message);
    }
}
```

### Q4: How do you enable JSON serialization in Spring Kafka?
**A:** Configure in application.properties:
```properties
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.trusted.packages=*
```

Then use POJOs directly:
```java
kafkaTemplate.send("orders", order);  // order is a POJO

@KafkaListener(topics = "orders")
public void consume(Order order) {}  // Automatic deserialization
```

### Q5: How do you manually commit offsets in Spring Kafka?
**A:**
1. Disable auto-commit:
```properties
spring.kafka.consumer.enable-auto-commit=false
```

2. Use Acknowledgment:
```java
@KafkaListener(topics = "orders")
public void consume(String message, Acknowledgment ack) {
    processMessage(message);
    ack.acknowledge();  // Manual commit
}
```

### Q6: How do you handle errors in Spring Kafka consumers?
**A:** Multiple approaches:
1. Try-catch in listener
2. Configure error handler
3. Use Dead Letter Queue (DLQ)

```java
@Bean
public ConcurrentKafkaListenerContainerFactory<String, String> factory() {
    factory.setErrorHandler(new SeekToCurrentErrorHandler(
        new DeadLetterPublishingRecoverer(kafkaTemplate),
        new FixedBackOff(1000L, 3)  // 3 retries
    ));
    return factory;
}
```

### Q7: What is a Dead Letter Queue (DLQ) in Kafka?
**A:** A DLQ is a topic where failed messages are sent after exhausting retries. Spring Kafka automatically creates a DLQ topic named `<original-topic>.DLT` when using DeadLetterPublishingRecoverer.

Failed messages can be consumed from DLQ for analysis or reprocessing.

### Q8: How do you consume messages in batches?
**A:**
```properties
spring.kafka.listener.type=batch
```

```java
@KafkaListener(topics = "orders")
public void consumeBatch(List<String> messages) {
    System.out.println("Batch size: " + messages.size());
    messages.forEach(this::processMessage);
}
```

### Q9: How do you access message metadata (offset, partition, topic)?
**A:**
```java
import org.apache.kafka.clients.consumer.ConsumerRecord;

@KafkaListener(topics = "orders")
public void consume(ConsumerRecord<String, String> record) {
    System.out.println("Topic: " + record.topic());
    System.out.println("Partition: " + record.partition());
    System.out.println("Offset: " + record.offset());
    System.out.println("Key: " + record.key());
    System.out.println("Value: " + record.value());
}
```

### Q10: How do you configure multiple Kafka consumers in the same application?
**A:** Use different groupId for each consumer:
```java
@KafkaListener(topics = "orders", groupId = "email-service")
public void emailConsumer(Order order) {}

@KafkaListener(topics = "orders", groupId = "analytics-service")
public void analyticsConsumer(Order order) {}
```
Both receive all messages independently.

### Q11: How do you send messages with headers in Spring Kafka?
**A:**
```java
import org.springframework.kafka.support.KafkaHeaders;
import org.springframework.messaging.Message;
import org.springframework.messaging.support.MessageBuilder;

Message<String> message = MessageBuilder
    .withPayload("order data")
    .setHeader(KafkaHeaders.TOPIC, "orders")
    .setHeader(KafkaHeaders.MESSAGE_KEY, "user123")
    .setHeader("correlation-id", "abc123")
    .build();

kafkaTemplate.send(message);
```

### Q12: How do you enable compression in Spring Kafka?
**A:**
```properties
spring.kafka.producer.compression-type=gzip
# Options: none, gzip, snappy, lz4, zstd
```

### Q13: What is the difference between @KafkaListener and KafkaTemplate?
**A:**
- **@KafkaListener**: Annotation for consuming messages (consumer)
- **KafkaTemplate**: Template class for sending messages (producer)

```java
// Consumer
@KafkaListener(topics = "orders")
public void consume(String msg) {}

// Producer
kafkaTemplate.send("orders", "message");
```

### Q14: How do you configure concurrent consumers in Spring Kafka?
**A:**
```properties
spring.kafka.listener.concurrency=3
```
Or programmatically:
```java
@KafkaListener(topics = "orders", groupId = "my-group", concurrency = "3")
public void consume(String message) {}
```
Creates 3 consumer threads for parallel processing.

### Q15: How do you test Kafka producers and consumers in Spring Boot?
**A:** Use `@EmbeddedKafka` for integration tests:
```java
import org.springframework.kafka.test.context.EmbeddedKafka;

@SpringBootTest
@EmbeddedKafka(partitions = 1, topics = {"test-topic"})
public class KafkaTest {
    
    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;
    
    @Test
    public void testSend() {
        kafkaTemplate.send("test-topic", "test message");
        // Assert consumer received message
    }
}
```

**End of Kafka Implementation!**