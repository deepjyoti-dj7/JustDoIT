# 04. Testing & Best Practices

## Testing Kafka Applications

### Testing Strategies

1. **Unit Tests**: Test business logic in isolation
2. **Integration Tests**: Test with embedded Kafka
3. **Contract Tests**: Verify producer-consumer contracts
4. **End-to-End Tests**: Test full system with real Kafka

---

## Unit Testing

### Mocking KafkaTemplate (Spring Boot)

```java
import static org.mockito.Mockito.*;

@ExtendWith(MockitoExtension.class)
public class OrderProducerTest {
    
    @Mock
    private KafkaTemplate<String, Order> kafkaTemplate;
    
    @InjectMocks
    private OrderProducer orderProducer;
    
    @Test
    public void testSendOrder() {
        Order order = new Order("123", "user1", 99.99);
        
        when(kafkaTemplate.send(anyString(), any(), any()))
            .thenReturn(mock(ListenableFuture.class));
        
        orderProducer.sendOrder(order);
        
        verify(kafkaTemplate).send(eq("orders"), eq("user1"), eq(order));
    }
}
```

### Testing Consumer Logic

```java
@Test
public void testOrderConsumer() {
    OrderConsumer consumer = new OrderConsumer();
    Order order = new Order("123", "user1", 99.99);
    
    // Test business logic directly
    consumer.processOrder(order);
    
    assertEquals("PROCESSED", order.getStatus());
}
```

---

## Integration Testing

### Embedded Kafka (Spring Boot)

```java
import org.springframework.kafka.test.context.EmbeddedKafka;

@SpringBootTest
@EmbeddedKafka(partitions = 1, topics = {"orders"}, 
               ports = {9092})
public class KafkaIntegrationTest {
    
    @Autowired
    private KafkaTemplate<String, Order> kafkaTemplate;
    
    @Autowired
    private OrderConsumer orderConsumer;
    
    @Test
    public void testProduceAndConsume() throws Exception {
        Order order = new Order("123", "user1", 99.99);
        
        // Produce
        kafkaTemplate.send("orders", "user1", order);
        
        // Wait for consumer
        Thread.sleep(2000);
        
        // Verify
        verify(orderConsumer).processOrder(any(Order.class));
    }
}
```

### Testcontainers (Docker-based Testing)

```java
import org.testcontainers.containers.KafkaContainer;
import org.testcontainers.utility.DockerImageName;

public class KafkaTestcontainersTest {
    
    static KafkaContainer kafka = new KafkaContainer(
        DockerImageName.parse("confluentinc/cp-kafka:latest")
    );
    
    @BeforeAll
    static void setup() {
        kafka.start();
        System.setProperty("spring.kafka.bootstrap-servers", 
                          kafka.getBootstrapServers());
    }
    
    @AfterAll
    static void teardown() {
        kafka.stop();
    }
    
    @Test
    public void testWithRealKafka() {
        // Test with actual Kafka container
    }
}
```

### Node.js Testing (Jest)

```javascript
const { Kafka } = require('kafkajs');

describe('Kafka Integration Tests', () => {
  let kafka, producer, consumer;
  
  beforeAll(async () => {
    kafka = new Kafka({
      clientId: 'test-app',
      brokers: ['localhost:9092']
    });
    
    producer = kafka.producer();
    consumer = kafka.consumer({ groupId: 'test-group' });
    
    await producer.connect();
    await consumer.connect();
  });
  
  afterAll(async () => {
    await producer.disconnect();
    await consumer.disconnect();
  });
  
  test('should produce and consume message', async () => {
    const messages = [];
    
    await consumer.subscribe({ topic: 'test-topic' });
    
    await consumer.run({
      eachMessage: async ({ message }) => {
        messages.push(message.value.toString());
      }
    });
    
    await producer.send({
      topic: 'test-topic',
      messages: [{ value: 'test message' }]
    });
    
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    expect(messages).toContain('test message');
  });
});
```

---

## Best Practices

## Producer Best Practices

### 1. Enable Idempotence

```java
props.put("enable.idempotence", true);
props.put("acks", "all");
props.put("retries", Integer.MAX_VALUE);
```

### 2. Use Compression

```java
props.put("compression.type", "gzip");
// Options: none, gzip, snappy, lz4, zstd
```

### 3. Batch Messages

```java
props.put("batch.size", 16384);
props.put("linger.ms", 10);
```

### 4. Handle Errors

```java
public void sendWithRetry(Order order) {
    int retries = 0;
    int maxRetries = 3;
    
    while (retries < maxRetries) {
        try {
            kafkaTemplate.send("orders", order).get(5, TimeUnit.SECONDS);
            return;
        } catch (Exception e) {
            retries++;
            if (retries >= maxRetries) {
                sendToDLQ(order, e);
            }
        }
    }
}
```

### 5. Use Appropriate Partitioning

```java
// Good: Partition by user ID for ordering
producer.send("orders", order.getUserId(), order);

// Bad: Random partitioning for ordered data
producer.send("orders", null, order);
```

---

## Consumer Best Practices

### 1. Idempotent Processing

```java
@KafkaListener(topics = "orders")
public void consume(Order order) {
    if (processedOrders.contains(order.getId())) {
        return; // Already processed
    }
    
    processOrder(order);
    processedOrders.add(order.getId());
}
```

### 2. Manual Offset Commit

```java
@KafkaListener(topics = "orders")
public void consume(Order order, Acknowledgment ack) {
    try {
        processOrder(order);
        ack.acknowledge(); // Commit only after success
    } catch (Exception e) {
        // Don't commit, will retry
        log.error("Failed to process order", e);
    }
}
```

### 3. Error Handling

```java
@KafkaListener(topics = "orders")
public void consume(Order order) {
    try {
        processOrder(order);
    } catch (RetryableException e) {
        throw e; // Kafka will retry
    } catch (NonRetryableException e) {
        sendToDLQ(order, e); // Don't retry
    }
}
```

### 4. Tune Fetch Settings

```properties
spring.kafka.consumer.max-poll-records=500
spring.kafka.consumer.fetch-min-size=1
spring.kafka.consumer.fetch-max-wait=500
```

### 5. Graceful Shutdown

```java
@PreDestroy
public void shutdown() {
    consumer.wakeup(); // Interrupt poll()
    latch.await(); // Wait for consumer to finish
}
```

---

## Topic Design Best Practices

### 1. Naming Convention

✅ **Good:**
```
user.created
order.placed
payment.completed
logs.application.error
```

❌ **Bad:**
```
data
events
topic1
```

### 2. Partition Count

**Formula:**
```
Partitions = max(
  throughput_required / throughput_per_partition,
  number_of_consumers
)
```

**Example:**
```
Target: 100 MB/s
Partition throughput: 10 MB/s
Partitions needed: 10
```

### 3. Replication Factor

```
Production: RF = 3
Development: RF = 1
Critical data: RF = 5
```

### 4. Retention

```properties
# Time-based
retention.ms=604800000  # 7 days

# Size-based
retention.bytes=1073741824  # 1 GB

# Compact (for changelog topics)
cleanup.policy=compact
```

---

## Performance Optimization

### Producer Tuning

```properties
# Throughput
batch.size=32768
linger.ms=20
compression.type=lz4
buffer.memory=67108864

# Latency
batch.size=0
linger.ms=0
acks=1
```

### Consumer Tuning

```properties
# Throughput
fetch.min.bytes=1048576
max.poll.records=1000

# Latency
fetch.min.bytes=1
max.poll.records=100
```

### Broker Tuning

```properties
num.network.threads=8
num.io.threads=16
socket.send.buffer.bytes=1048576
socket.receive.buffer.bytes=1048576
```

---

## Monitoring Best Practices

### Key Metrics

**Producer:**
- Request rate
- Request latency
- Error rate
- Batch size

**Consumer:**
- Lag (most important)
- Commit rate
- Poll latency
- Rebalance rate

**Broker:**
- Under-replicated partitions
- Leader election rate
- Request queue size
- Disk usage

### Alerting Thresholds

```
Consumer Lag > 10,000: WARNING
Consumer Lag > 100,000: CRITICAL

Under-replicated partitions > 0: CRITICAL

Disk usage > 80%: WARNING
Disk usage > 90%: CRITICAL
```

---

## Security Best Practices

### 1. Enable Authentication (SASL)

```properties
security.protocol=SASL_SSL
sasl.mechanism=PLAIN
```

### 2. Enable Encryption (SSL/TLS)

```properties
ssl.keystore.location=/var/ssl/kafka.keystore.jks
ssl.keystore.password=password
ssl.key.password=password
```

### 3. Use ACLs

```bash
kafka-acls.sh --add --allow-principal User:alice \
  --operation Read --topic orders
```

### 4. Rotate Credentials

- Rotate passwords regularly
- Use secret management (Vault, AWS Secrets Manager)
- Monitor unauthorized access

---

## Deployment Best Practices

### 1. Cluster Sizing

**Minimum production:**
```
3 Brokers
3 ZooKeeper nodes (or KRaft mode)
2 Schema Registry instances
```

### 2. Resource Allocation

```
Broker:
  CPU: 8-16 cores
  RAM: 32-64 GB
  Disk: SSD (1-2 TB)

ZooKeeper:
  CPU: 4 cores
  RAM: 8 GB
  Disk: SSD (100 GB)
```

### 3. Network

- Dedicated network for Kafka traffic
- 10 Gbps network recommended
- Low latency between brokers

### 4. Monitoring

- Prometheus + Grafana
- Datadog / New Relic
- Confluent Control Center

---

## Common Pitfalls

### 1. Too Many Partitions

❌ **Problem:** 1000+ partitions per topic
✅ **Solution:** Start with 10-30, scale as needed

### 2. Not Using Message Keys

❌ **Problem:** Messages for same entity in different partitions
✅ **Solution:** Use entity ID as key

### 3. Ignoring Consumer Lag

❌ **Problem:** Lag grows indefinitely
✅ **Solution:** Monitor and alert on lag

### 4. No Dead Letter Queue

❌ **Problem:** Failed messages block processing
✅ **Solution:** Implement DLQ for failed messages

### 5. Default Configurations

❌ **Problem:** Using defaults in production
✅ **Solution:** Tune based on workload

---

## Summary

**Testing:**
- Unit tests: Mock Kafka clients
- Integration tests: Embedded Kafka / Testcontainers
- End-to-end tests: Real Kafka cluster

**Producer Best Practices:**
- Enable idempotence
- Use compression
- Batch messages
- Handle errors

**Consumer Best Practices:**
- Idempotent processing
- Manual offset commit
- Graceful shutdown
- Monitor lag

**Performance:**
- Tune batch size and linger
- Optimize partitions
- Monitor metrics

---

## Interview Questions & Answers

### Q1: How do you test Kafka applications?
**A:**
- **Unit tests**: Mock KafkaTemplate/Consumer, test business logic
- **Integration tests**: Use @EmbeddedKafka or Testcontainers
- **Contract tests**: Verify producer-consumer schemas
- **E2E tests**: Test with real Kafka cluster

### Q2: What is @EmbeddedKafka in Spring Boot?
**A:** `@EmbeddedKafka` starts an in-memory Kafka broker for integration testing:
```java
@SpringBootTest
@EmbeddedKafka(partitions = 1, topics = {"test-topic"})
public class KafkaTest { ... }
```
Useful for testing without external dependencies.

### Q3: How do you ensure idempotent processing in consumers?
**A:**
1. Track processed message IDs in database
2. Check if already processed before handling
3. Use unique keys or offsets as deduplication IDs
4. Design operations to be naturally idempotent (upsert vs insert)

### Q4: What are the key producer configurations for production?
**A:**
```properties
enable.idempotence=true
acks=all
compression.type=lz4
retries=Integer.MAX_VALUE
batch.size=16384
linger.ms=10
```

### Q5: How do you handle consumer lag?
**A:**
1. **Monitor**: Set alerts for lag thresholds
2. **Scale**: Add more consumers (up to partition count)
3. **Optimize**: Improve processing speed
4. **Batch**: Process multiple messages together
5. **Increase fetch size**: Reduce network overhead

### Q6: What is a dead letter queue (DLQ)?
**A:** A DLQ is a topic where failed messages are sent after exhausting retries. Prevents poison messages from blocking processing. Messages in DLQ can be analyzed, fixed, and replayed.

### Q7: How many partitions should a topic have?
**A:** Formula: `max(throughput_needed / partition_throughput, number_of_consumers)`

Guidelines:
- Start with 10-30 partitions
- High throughput: 50-100 partitions
- Too many (1000+) causes overhead

### Q8: What is the recommended replication factor?
**A:**
- **Production**: 3 (can survive 2 broker failures)
- **Critical data**: 5
- **Development**: 1

With `min.insync.replicas=2`, RF=3 allows 1 broker down while accepting writes.

### Q9: How do you optimize Kafka performance?
**A:**
**Producer:**
- Batch messages (`batch.size`, `linger.ms`)
- Enable compression
- Async sends

**Consumer:**
- Batch processing
- Increase `fetch.min.bytes`
- Parallel processing within consumer

**Broker:**
- Use SSDs
- Tune `num.io.threads`
- Optimize JVM heap

### Q10: What is the difference between `acks=1` and `acks=all`?
**A:**
- `acks=1`: Leader acknowledges (fast, may lose data if leader fails)
- `acks=all`: All ISRs acknowledge (safe, no data loss, slower)

Use `acks=all` for critical data.

### Q11: How do you implement graceful shutdown for consumers?
**A:**
```java
@PreDestroy
public void shutdown() {
    consumer.wakeup(); // Interrupt ongoing poll
    shutdownLatch.await(); // Wait for consumer to finish
}
```
Ensures in-flight messages are processed before stopping.

### Q12: What metrics should you monitor in Kafka?
**A:**
**Consumer:**
- Lag (most important)
- Commit failures
- Rebalance rate

**Producer:**
- Request latency
- Error rate
- Batch size

**Broker:**
- Under-replicated partitions
- Disk usage
- Request queue size

### Q13: How do you test Kafka with Testcontainers?
**A:**
```java
KafkaContainer kafka = new KafkaContainer(
    DockerImageName.parse("confluentinc/cp-kafka:latest")
);
kafka.start();

// Use kafka.getBootstrapServers() for connection
```
Starts real Kafka in Docker for integration tests.

### Q14: What is compaction in Kafka?
**A:** Compaction keeps only the latest value for each key, removing old duplicates:
```properties
cleanup.policy=compact
```
Useful for changelog topics and state stores. Messages with same key are compacted, keeping latest.

### Q15: How do you secure Kafka?
**A:**
1. **Authentication**: SASL (PLAIN, SCRAM, GSSAPI)
2. **Encryption**: SSL/TLS for data in transit
3. **Authorization**: ACLs for topic/consumer group access
4. **Network**: Private VPC, firewalls
5. **Monitoring**: Audit unauthorized access attempts

**Next:** Docker & Deployment!