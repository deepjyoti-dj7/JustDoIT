# 06. Security & Monitoring

## Kafka Security

### Security Components

1. **Authentication**: Verify identity (SASL)
2. **Authorization**: Control access (ACLs)
3. **Encryption**: Protect data in transit (SSL/TLS)
4. **Encryption at rest**: Protect data on disk

---

## Authentication (SASL)

### SASL Mechanisms

| Mechanism | Description | Use Case |
|-----------|-------------|----------|
| **PLAIN** | Username/password (simple) | Development |
| **SCRAM** | Username/password (hashed) | Production |
| **GSSAPI** | Kerberos | Enterprise |
| **OAUTHBEARER** | OAuth 2.0 tokens | Modern apps |

---

### SASL/PLAIN Configuration

#### Broker (server.properties)

```properties
listeners=SASL_PLAINTEXT://localhost:9092
security.inter.broker.protocol=SASL_PLAINTEXT
sasl.mechanism.inter.broker.protocol=PLAIN
sasl.enabled.mechanisms=PLAIN

# JAAS configuration file
listener.name.sasl_plaintext.plain.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
  username="admin" \
  password="admin-secret" \
  user_admin="admin-secret" \
  user_alice="alice-secret";
```

#### Producer (Spring Boot)

```properties
spring.kafka.bootstrap-servers=localhost:9092
spring.kafka.security.protocol=SASL_PLAINTEXT
spring.kafka.properties.sasl.mechanism=PLAIN
spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required \
  username="alice" \
  password="alice-secret";
```

#### Consumer (Node.js)

```javascript
const kafka = new Kafka({
  brokers: ['localhost:9092'],
  sasl: {
    mechanism: 'plain',
    username: 'alice',
    password: 'alice-secret'
  }
});
```

---

### SASL/SCRAM Configuration

#### Create User

```bash
kafka-configs.sh --zookeeper localhost:2181 \
  --alter --add-config 'SCRAM-SHA-256=[password=alice-secret]' \
  --entity-type users --entity-name alice
```

#### Broker Configuration

```properties
listeners=SASL_PLAINTEXT://localhost:9092
security.inter.broker.protocol=SASL_PLAINTEXT
sasl.mechanism.inter.broker.protocol=SCRAM-SHA-256
sasl.enabled.mechanisms=SCRAM-SHA-256
```

#### Client Configuration

```properties
security.protocol=SASL_PLAINTEXT
sasl.mechanism=SCRAM-SHA-256
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
  username="alice" \
  password="alice-secret";
```

---

## Encryption (SSL/TLS)

### Generate Certificates

#### 1. Create CA (Certificate Authority)

```bash
openssl req -new -x509 -keyout ca-key -out ca-cert -days 365
```

#### 2. Create Keystore for Broker

```bash
keytool -keystore kafka.server.keystore.jks -alias localhost \
  -validity 365 -genkey -keyalg RSA
```

#### 3. Create Certificate Signing Request

```bash
keytool -keystore kafka.server.keystore.jks -alias localhost \
  -certreq -file cert-file
```

#### 4. Sign Certificate

```bash
openssl x509 -req -CA ca-cert -CAkey ca-key \
  -in cert-file -out cert-signed -days 365 -CAcreateserial
```

#### 5. Import Certificates

```bash
keytool -keystore kafka.server.keystore.jks -alias CARoot -import -file ca-cert
keytool -keystore kafka.server.keystore.jks -alias localhost -import -file cert-signed
```

### Broker Configuration (SSL)

```properties
listeners=SSL://localhost:9093
security.inter.broker.protocol=SSL

ssl.keystore.location=/var/ssl/kafka.server.keystore.jks
ssl.keystore.password=keystore-password
ssl.key.password=key-password

ssl.truststore.location=/var/ssl/kafka.server.truststore.jks
ssl.truststore.password=truststore-password

ssl.client.auth=required
```

### Client Configuration (SSL)

```properties
security.protocol=SSL
ssl.truststore.location=/var/ssl/kafka.client.truststore.jks
ssl.truststore.password=truststore-password

ssl.keystore.location=/var/ssl/kafka.client.keystore.jks
ssl.keystore.password=keystore-password
ssl.key.password=key-password
```

---

## SASL + SSL (Production)

### Broker Configuration

```properties
listeners=SASL_SSL://localhost:9093
security.inter.broker.protocol=SASL_SSL
sasl.mechanism.inter.broker.protocol=SCRAM-SHA-256
sasl.enabled.mechanisms=SCRAM-SHA-256

# SSL
ssl.keystore.location=/var/ssl/kafka.server.keystore.jks
ssl.keystore.password=keystore-password
ssl.key.password=key-password
ssl.truststore.location=/var/ssl/kafka.server.truststore.jks
ssl.truststore.password=truststore-password
```

### Client Configuration

```properties
security.protocol=SASL_SSL
sasl.mechanism=SCRAM-SHA-256
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
  username="alice" \
  password="alice-secret";

ssl.truststore.location=/var/ssl/kafka.client.truststore.jks
ssl.truststore.password=truststore-password
```

---

## Authorization (ACLs)

### Enable ACLs

```properties
authorizer.class.name=kafka.security.authorizer.AclAuthorizer
super.users=User:admin
```

### Grant Permissions

#### Allow Read on Topic

```bash
kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2181 \
  --add --allow-principal User:alice \
  --operation Read --topic orders
```

#### Allow Write on Topic

```bash
kafka-acls.sh --add --allow-principal User:alice \
  --operation Write --topic orders \
  --bootstrap-server localhost:9092
```

#### Allow Consumer Group

```bash
kafka-acls.sh --add --allow-principal User:alice \
  --operation Read --group my-consumer-group \
  --bootstrap-server localhost:9092
```

### List ACLs

```bash
kafka-acls.sh --list --topic orders \
  --bootstrap-server localhost:9092
```

### Remove ACL

```bash
kafka-acls.sh --remove --allow-principal User:alice \
  --operation Read --topic orders \
  --bootstrap-server localhost:9092
```

---

## Monitoring

### Key Metrics

#### Broker Metrics

| Metric | Description | Alert Threshold |
|--------|-------------|----------------|
| **UnderReplicatedPartitions** | Partitions not fully replicated | > 0 |
| **OfflinePartitionsCount** | Partitions with no leader | > 0 |
| **ActiveControllerCount** | Active controller count | != 1 |
| **RequestQueueSize** | Pending requests | > 1000 |
| **BytesInPerSec** | Incoming bytes/sec | - |
| **BytesOutPerSec** | Outgoing bytes/sec | - |

#### Producer Metrics

| Metric | Description |
|--------|-------------|
| **record-send-rate** | Messages sent/sec |
| **request-latency-avg** | Average latency |
| **record-error-rate** | Failed messages/sec |
| **batch-size-avg** | Average batch size |

#### Consumer Metrics

| Metric | Description | Alert Threshold |
|--------|-------------|----------------|
| **records-lag-max** | Max lag across partitions | > 10000 |
| **records-consumed-rate** | Records/sec consumed | - |
| **commit-latency-avg** | Offset commit latency | > 1000ms |
| **fetch-latency-avg** | Fetch latency | > 500ms |

---

### Prometheus & Grafana

#### JMX Exporter for Kafka

```bash
# Download JMX exporter
wget https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.18.0/jmx_prometheus_javaagent-0.18.0.jar
```

#### kafka-jmx-config.yml

```yaml
lowercaseOutputName: true
rules:
  - pattern: kafka.server<type=(.+), name=(.+)><>Value
    name: kafka_server_$1_$2
  - pattern: kafka.server<type=(.+), name=(.+), topic=(.+)><>Count
    name: kafka_server_$1_$2
    labels:
      topic: "$3"
```

#### Start Kafka with JMX Exporter

```bash
export KAFKA_OPTS="-javaagent:/path/to/jmx_prometheus_javaagent-0.18.0.jar=7071:/path/to/kafka-jmx-config.yml"
kafka-server-start.sh config/server.properties
```

#### Prometheus Configuration

```yaml
scrape_configs:
  - job_name: 'kafka'
    static_configs:
      - targets: ['localhost:7071', 'localhost:7072', 'localhost:7073']
```

#### Grafana Dashboard

Import dashboard ID: **721** (Kafka Overview)

---

### Kafka Manager / Kafka UI

#### Kafka UI (Docker)

```yaml
kafka-ui:
  image: provectuslabs/kafka-ui:latest
  ports:
    - "8080:8080"
  environment:
    KAFKA_CLUSTERS_0_NAME: local
    KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
```

Access at: `http://localhost:8080`

---

### Confluent Control Center

```yaml
control-center:
  image: confluentinc/cp-enterprise-control-center:7.5.0
  depends_on:
    - kafka
  ports:
    - "9021:9021"
  environment:
    CONTROL_CENTER_BOOTSTRAP_SERVERS: kafka:9092
    CONTROL_CENTER_REPLICATION_FACTOR: 1
```

Access at: `http://localhost:9021`

---

### Monitoring Best Practices

#### Alerting Rules

```yaml
groups:
  - name: kafka
    rules:
      - alert: KafkaHighLag
        expr: kafka_consumergroup_lag > 10000
        for: 5m
        annotations:
          summary: "High consumer lag"
          
      - alert: UnderReplicatedPartitions
        expr: kafka_server_replicamanager_underreplicatedpartitions > 0
        for: 5m
        annotations:
          summary: "Partitions under-replicated"
          
      - alert: OfflinePartitions
        expr: kafka_controller_kafkacontroller_offlinepartitionscount > 0
        for: 1m
        annotations:
          summary: "Offline partitions detected"
```

---

## Summary

**Authentication:**
- SASL/PLAIN: Simple (dev)
- SASL/SCRAM: Secure (prod)
- SASL/GSSAPI: Kerberos (enterprise)

**Authorization:**
- ACLs for fine-grained access control
- Grant read/write per topic/consumer group

**Encryption:**
- SSL/TLS for data in transit
- Certificate-based authentication

**Monitoring:**
- JMX metrics â†’ Prometheus â†’ Grafana
- Key metrics: lag, under-replicated partitions, throughput
- Kafka UI, Control Center for visualization

---

## Interview Questions & Answers

### Q1: How do you enable authentication in Kafka?
**A:** Use SASL (Simple Authentication and Security Layer):
```properties
listeners=SASL_PLAINTEXT://localhost:9092
sasl.enabled.mechanisms=SCRAM-SHA-256
```
Clients authenticate with username/password.

### Q2: What SASL mechanisms does Kafka support?
**A:**
- **PLAIN**: Username/password (plaintext, dev only)
- **SCRAM**: Username/password (hashed, production)
- **GSSAPI**: Kerberos (enterprise)
- **OAUTHBEARER**: OAuth 2.0 tokens

### Q3: How do you enable SSL/TLS encryption in Kafka?
**A:**
1. Generate keystore and truststore
2. Configure broker:
```properties
listeners=SSL://localhost:9093
ssl.keystore.location=/var/ssl/kafka.server.keystore.jks
ssl.keystore.password=password
```
3. Configure clients with truststore

### Q4: What are ACLs in Kafka?
**A:** Access Control Lists (ACLs) define permissions for users/principals:
- Read/Write on topics
- Consume from consumer groups
- Create/Delete topics

Example:
```bash
kafka-acls.sh --add --allow-principal User:alice \
  --operation Read --topic orders
```

### Q5: What is the difference between SASL_PLAINTEXT and SASL_SSL?
**A:**
- **SASL_PLAINTEXT**: Authentication only (no encryption)
- **SASL_SSL**: Authentication + SSL encryption (production recommended)

### Q6: What key metrics should you monitor in Kafka?
**A:**
**Broker:**
- Under-replicated partitions (should be 0)
- Offline partitions (should be 0)
- Request queue size

**Consumer:**
- Consumer lag (critical)
- Commit latency

**Producer:**
- Request latency
- Error rate

### Q7: How do you monitor consumer lag?
**A:**
Multiple ways:
1. **kafka-consumer-groups.sh**:
```bash
kafka-consumer-groups.sh --describe --group my-group
```
2. **JMX metrics**: `kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*`
3. **Prometheus + Grafana**: Export JMX metrics
4. **Burrow**: LinkedIn's consumer lag monitoring tool

### Q8: What is JMX in Kafka?
**A:** Java Management Extensions (JMX) exposes Kafka metrics for monitoring:
- Broker metrics (under-replicated partitions, throughput)
- Producer/consumer metrics (latency, error rate)

Export via JMX exporter to Prometheus.

### Q9: How do you set up Prometheus monitoring for Kafka?
**A:**
1. Download JMX Prometheus exporter
2. Configure `kafka-jmx-config.yml`
3. Start Kafka with exporter:
```bash
export KAFKA_OPTS="-javaagent:jmx_prometheus_javaagent.jar=7071:config.yml"
```
4. Configure Prometheus to scrape port 7071
5. Visualize in Grafana

### Q10: What is Confluent Control Center?
**A:** Confluent Control Center is a web-based UI for managing and monitoring Kafka clusters:
- View topics, partitions, consumer groups
- Monitor throughput, latency, lag
- Schema Registry management
- Alerting and notifications

### Q11: How do you create a user for SASL/SCRAM?
**A:**
```bash
kafka-configs.sh --zookeeper localhost:2181 \
  --alter --add-config 'SCRAM-SHA-256=[password=secret]' \
  --entity-type users --entity-name alice
```

### Q12: What are super users in Kafka?
**A:** Super users have all permissions without explicit ACLs:
```properties
super.users=User:admin;User:kafka
```
Used for admin accounts and inter-broker communication.

### Q13: How do you rotate SSL certificates in Kafka?
**A:**
1. Generate new certificate
2. Add to keystore alongside old cert
3. Rolling restart brokers one by one
4. Update clients to use new cert
5. Remove old cert after all clients updated

No downtime with rolling restart.

### Q14: What is the recommended alert for under-replicated partitions?
**A:** Alert immediately when under-replicated partitions > 0:
```yaml
alert: UnderReplicatedPartitions
expr: kafka_server_replicamanager_underreplicatedpartitions > 0
for: 5m
```
Indicates replica not in sync, risk of data loss.

### Q15: How do you secure Kafka in production?
**A:**
1. **Authentication**: SASL/SCRAM or SASL/GSSAPI
2. **Encryption**: SSL/TLS for all connections
3. **Authorization**: Enable ACLs, least privilege
4. **Network**: VPC, security groups, firewall rules
5. **Secrets**: Vault, AWS Secrets Manager for credentials
6. **Monitoring**: Audit logs, unauthorized access alerts

**ðŸŽ‰ Kafka Content Complete! All folders done!**