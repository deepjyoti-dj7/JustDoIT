# ğŸŒŠ Collection to Stream

## ğŸ“– Overview

**Streams** provide a functional approach to process collections. A stream is a sequence of elements that supports sequential and parallel aggregate operations.

```java
List<Integer> list = Arrays.asList(1, 2, 3, 4, 5);
Stream<Integer> stream = list.stream();
```

**Key point**: Streams don't store data, they operate on data from a source (collection, array, I/O).

---

## â­ Key Characteristics

1. **No storage** - Streams don't store elements
2. **Functional** - Operations produce results without modifying source
3. **Lazy** - Intermediate operations are lazy (executed on terminal operation)
4. **Possibly unbounded** - Can work with infinite streams
5. **Consumable** - Can be traversed only once
6. **Pipeline** - Chain operations: source â†’ intermediate â†’ terminal

---

## ğŸ’» Creating Streams

### 1. From Collections
```java
List<String> list = Arrays.asList("A", "B", "C");

// Sequential stream
Stream<String> stream = list.stream();

// Parallel stream
Stream<String> parallelStream = list.parallelStream();
```

### 2. From Arrays
```java
// Object array
String[] array = {"A", "B", "C"};
Stream<String> stream = Arrays.stream(array);

// Primitive array
int[] numbers = {1, 2, 3, 4, 5};
IntStream intStream = Arrays.stream(numbers);
```

### 3. From Values
```java
// Stream.of()
Stream<String> stream = Stream.of("A", "B", "C");

// Single element
Stream<String> single = Stream.of("A");

// Empty stream
Stream<String> empty = Stream.empty();
```

### 4. From Files
```java
// Read lines from file
try (Stream<String> lines = Files.lines(Paths.get("file.txt"))) {
    lines.forEach(System.out::println);
}
```

### 5. Generate Infinite Streams
```java
// Infinite stream with supplier
Stream<Double> randoms = Stream.generate(Math::random);

// Infinite stream with seed and function
Stream<Integer> numbers = Stream.iterate(0, n -> n + 1);  // 0, 1, 2, 3...

// Limited infinite stream
Stream<Integer> limited = Stream.iterate(0, n -> n + 1).limit(10);
```

### 6. From Ranges
```java
// IntStream range
IntStream range = IntStream.range(1, 5);  // 1, 2, 3, 4 (exclusive end)
IntStream rangeClosed = IntStream.rangeClosed(1, 5);  // 1, 2, 3, 4, 5 (inclusive)

// Convert to Stream<Integer>
Stream<Integer> stream = range.boxed();
```

---

## ğŸ”„ Stream Pipeline

```java
List<Integer> numbers = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);

// Pipeline: source â†’ intermediate â†’ terminal
List<Integer> result = numbers.stream()              // Source
    .filter(n -> n % 2 == 0)                        // Intermediate
    .map(n -> n * 2)                                // Intermediate
    .collect(Collectors.toList());                  // Terminal

System.out.println(result);  // [4, 8, 12, 16, 20]
```

**Pipeline stages:**
1. **Source** - Collection, array, generator
2. **Intermediate operations** - filter, map, sorted (lazy, return stream)
3. **Terminal operation** - collect, forEach, reduce (triggers execution)

---

## ğŸ¯ Real-World Examples

### 1. Process Employee Data
```java
class Employee {
    String name;
    String department;
    double salary;
}

List<Employee> employees = getEmployees();

// Get names of high earners in Engineering
List<String> names = employees.stream()
    .filter(e -> e.department.equals("Engineering"))
    .filter(e -> e.salary > 100000)
    .map(Employee::getName)
    .collect(Collectors.toList());
```

---

### 2. Process Order List
```java
class Order {
    String id;
    double amount;
    String status;
}

List<Order> orders = getOrders();

// Calculate total revenue from completed orders
double revenue = orders.stream()
    .filter(o -> o.status.equals("COMPLETED"))
    .mapToDouble(Order::getAmount)
    .sum();

System.out.println("Revenue: $" + revenue);
```

---

### 3. File Processing
```java
// Count lines containing "error" in log file
try (Stream<String> lines = Files.lines(Paths.get("app.log"))) {
    long errorCount = lines
        .filter(line -> line.contains("error"))
        .count();
    
    System.out.println("Errors: " + errorCount);
}
```

---

### 4. Generate Test Data
```java
// Generate 10 random user IDs
List<String> userIds = Stream.generate(() -> "USER_" + UUID.randomUUID())
    .limit(10)
    .collect(Collectors.toList());
```

---

### 5. Number Sequence
```java
// Generate Fibonacci sequence (first 10 numbers)
Stream.iterate(new int[]{0, 1}, f -> new int[]{f[1], f[0] + f[1]})
    .limit(10)
    .map(f -> f[0])
    .forEach(System.out::println);
// 0, 1, 1, 2, 3, 5, 8, 13, 21, 34
```

---

## ğŸ”€ Sequential vs Parallel Streams

### Sequential Stream
```java
List<Integer> numbers = Arrays.asList(1, 2, 3, 4, 5);

// Sequential processing
long sum = numbers.stream()
    .mapToLong(Integer::longValue)
    .sum();
```

### Parallel Stream
```java
// Parallel processing (uses ForkJoinPool)
long sum = numbers.parallelStream()
    .mapToLong(Integer::longValue)
    .sum();

// Or convert to parallel
long sum2 = numbers.stream()
    .parallel()
    .mapToLong(Integer::longValue)
    .sum();
```

**When to use parallel:**
- Large datasets (> 10,000 elements)
- CPU-intensive operations
- Independent operations (no shared state)

**When NOT to use parallel:**
- Small datasets
- I/O operations
- Order matters
- Operations have side effects

---

## âš ï¸ Common Pitfalls

1. **Reusing streams**
```java
Stream<Integer> stream = list.stream();
stream.forEach(System.out::println);

// âŒ IllegalStateException - stream already operated upon
stream.forEach(System.out::println);

// âœ… Create new stream
list.stream().forEach(System.out::println);
```

2. **Modifying source during stream**
```java
List<Integer> list = new ArrayList<>(Arrays.asList(1, 2, 3));

// âŒ ConcurrentModificationException
list.stream().forEach(n -> list.add(n * 2));

// âœ… Collect to new list
List<Integer> doubled = list.stream()
    .map(n -> n * 2)
    .collect(Collectors.toList());
```

3. **Forgetting terminal operation**
```java
List<Integer> list = Arrays.asList(1, 2, 3, 4, 5);

// âŒ Nothing happens - no terminal operation
list.stream()
    .filter(n -> n % 2 == 0)
    .map(n -> n * 2);

// âœ… Add terminal operation
list.stream()
    .filter(n -> n % 2 == 0)
    .map(n -> n * 2)
    .collect(Collectors.toList());
```

4. **Side effects in parallel streams**
```java
List<Integer> list = Arrays.asList(1, 2, 3, 4, 5);
List<Integer> result = new ArrayList<>();

// âŒ Race condition with parallel stream
list.parallelStream().forEach(result::add);

// âœ… Use collect
List<Integer> result2 = list.parallelStream()
    .collect(Collectors.toList());
```

5. **Infinite streams without limit**
```java
// âŒ Never terminates
Stream.generate(Math::random)
    .forEach(System.out::println);

// âœ… Add limit
Stream.generate(Math::random)
    .limit(10)
    .forEach(System.out::println);
```

---

## ğŸ’¡ Best Practices

1. **Use appropriate stream type**
```java
// âœ… Use primitive streams for primitives
int[] arr = {1, 2, 3, 4, 5};
int sum = Arrays.stream(arr).sum();  // IntStream

// âŒ Avoid boxing/unboxing
int sum2 = Arrays.stream(arr)
    .boxed()
    .mapToInt(Integer::intValue)
    .sum();
```

2. **Close streams from I/O**
```java
// âœ… Use try-with-resources
try (Stream<String> lines = Files.lines(Paths.get("file.txt"))) {
    lines.forEach(System.out::println);
}
```

3. **Don't overuse parallel streams**
```java
// âŒ Parallel for small list
List<Integer> small = Arrays.asList(1, 2, 3);
small.parallelStream().forEach(System.out::println);

// âœ… Use sequential for small lists
small.stream().forEach(System.out::println);
```

4. **Avoid stateful operations**
```java
// âŒ Stateful lambda
int[] counter = {0};
list.stream().forEach(n -> counter[0]++);

// âœ… Use count()
long count = list.stream().count();
```

---

## ğŸ“Š Stream vs Collection

| Feature | Collection | Stream |
|---------|-----------|--------|
| **Storage** | Stores elements | No storage |
| **Modification** | Can modify | Cannot modify source |
| **Traversal** | Multiple times | Once only |
| **Construction** | Eager | Lazy |
| **Operations** | External iteration | Internal iteration |

```java
List<Integer> list = Arrays.asList(1, 2, 3, 4, 5);

// Collection - external iteration
for (Integer n : list) {
    System.out.println(n);
}

// Stream - internal iteration
list.stream().forEach(System.out::println);
```

---

## ğŸ“ When to Use Streams

### âœ… Use Streams When:
- Functional-style operations (filter, map, reduce)
- Chaining multiple operations
- Need parallel processing
- Working with large datasets
- Clean, readable code

### âŒ Don't Use When:
- Simple iteration
- Need to modify source
- Multiple traversals needed
- Index-based access required
- Very small datasets (overhead not worth it)

---

## ğŸ“š Interview Questions

**Q1: What is a Stream?**
A: Sequence of elements supporting sequential and parallel operations. Doesn't store data.

**Q2: Stream vs Collection?**
A: Collection stores data, Stream processes data. Stream is lazy, Collection is eager.

**Q3: Can you reuse a stream?**
A: No, streams can be consumed only once. Create new stream for reuse.

**Q4: What are intermediate operations?**
A: Operations that return Stream (filter, map, sorted). Lazy - executed when terminal operation is called.

**Q5: What are terminal operations?**
A: Operations that produce result or side effect (collect, forEach, reduce). Trigger pipeline execution.

**Q6: When to use parallel streams?**
A: Large datasets (>10K elements), CPU-intensive, independent operations.

**Q7: How to create stream from array?**
A: Arrays.stream(array) or Stream.of(array).

**Q8: What happens if you forget terminal operation?**
A: Nothing - stream pipeline doesn't execute without terminal operation.

---

## ğŸ“š Summary

- **Streams**: Functional approach to process collections
- **No storage**: Operate on data from source
- **Lazy**: Intermediate operations are lazy
- **Consumable**: Can traverse only once
- **Pipeline**: source â†’ intermediate â†’ terminal
- **Creation**: stream(), Arrays.stream(), Stream.of(), generate(), iterate()
- **Parallel**: parallelStream() for large datasets
- **Best practice**: Use appropriate stream type, close I/O streams, avoid parallel for small data
