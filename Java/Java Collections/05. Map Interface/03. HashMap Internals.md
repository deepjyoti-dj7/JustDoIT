# ‚öôÔ∏è HashMap Internals

## üìñ Overview

Understanding HashMap internals is crucial for **optimizing performance** and **avoiding common pitfalls**. HashMap uses **hashing, bucketing, and collision resolution** for O(1) operations.

---

## üèóÔ∏è Internal Structure

```java
public class HashMap<K,V> {
    // Array of buckets (nodes)
    transient Node<K,V>[] table;
    
    // Number of key-value pairs
    transient int size;
    
    // Resize threshold = capacity * loadFactor
    int threshold;
    
    // Load factor (default 0.75)
    final float loadFactor;
    
    // Default initial capacity (must be power of 2)
    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // 16
    
    // Maximum capacity
    static final int MAXIMUM_CAPACITY = 1 << 30;
    
    // Treeify threshold (linked list to tree)
    static final int TREEIFY_THRESHOLD = 8;
    
    // Untreeify threshold (tree to linked list)
    static final int UNTREEIFY_THRESHOLD = 6;
}
```

---

## üîó Node Structure

```java
// Linked list node (Java 8+)
static class Node<K,V> implements Map.Entry<K,V> {
    final int hash;      // Cached hash code
    final K key;         // Key
    V value;             // Value
    Node<K,V> next;      // Next node in bucket (collision chain)
    
    Node(int hash, K key, V value, Node<K,V> next) {
        this.hash = hash;
        this.key = key;
        this.value = value;
        this.next = next;
    }
    
    public final K getKey()        { return key; }
    public final V getValue()      { return value; }
    public final V setValue(V newValue) {
        V oldValue = value;
        value = newValue;
        return oldValue;
    }
}

// Tree node (when bucket becomes tree)
static final class TreeNode<K,V> extends LinkedHashMap.Entry<K,V> {
    TreeNode<K,V> parent;
    TreeNode<K,V> left;
    TreeNode<K,V> right;
    TreeNode<K,V> prev;
    boolean red;
    // Red-Black Tree implementation
}
```

---

## üî¢ Hash Function

```java
// HashMap's hash function (Java 8+)
static final int hash(Object key) {
    int h;
    // XOR higher bits with lower bits for better distribution
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}

// Index calculation
// index = hash & (capacity - 1)
// Equivalent to: hash % capacity (but faster for power of 2)

// Example:
// hash = 123456
// capacity = 16 (binary: 10000)
// capacity - 1 = 15 (binary: 01111)
// index = 123456 & 15 = 0 (using last 4 bits)
```

**Why XOR with upper bits?**
- Spreads hash values better
- Reduces collisions
- Works well with power-of-2 capacity

---

## üìä Visual Representation

```
HashMap with capacity 16, size 5:

Index  Bucket
  0  -> [null]
  1  -> [null]
  2  -> [Node(hash=34, key="Alice", value=25)] -> [Node(hash=50, key="Bob", value=30)]
  3  -> [null]
  4  -> [Node(hash=68, key="Charlie", value=35)]
  5  -> [null]
  6  -> [Node(hash=86, key="David", value=40)]
  7  -> [null]
  8  -> [null]
  9  -> [Node(hash=105, key="Eve", value=28)]
 10  -> [null]
 11  -> [null]
 12  -> [null]
 13  -> [null]
 14  -> [null]
 15  -> [null]

- Bucket 2 has collision (linked list)
- Empty buckets waste space but provide fast access
- Load factor controls balance between space and collisions
```

---

## üîÑ put() Operation Flow

```java
// Simplified put() logic
public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}

final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) {
    Node<K,V>[] tab;
    Node<K,V> p;
    int n, i;
    
    // 1. If table is null or empty, resize
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    
    // 2. Calculate index: i = hash & (n - 1)
    // 3. If bucket is empty, create new node
    if ((p = tab[i = (n - 1) & hash]) == null)
        tab[i] = newNode(hash, key, value, null);
    else {
        // 4. Collision handling
        Node<K,V> e; K k;
        
        // 4a. If first node has same key, found it
        if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k))))
            e = p;
        
        // 4b. If bucket is a tree, insert in tree
        else if (p instanceof TreeNode)
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        
        // 4c. Traverse linked list
        else {
            for (int binCount = 0; ; ++binCount) {
                if ((e = p.next) == null) {
                    // Add to end of list
                    p.next = newNode(hash, key, value, null);
                    
                    // If list too long (>= 8), convert to tree
                    if (binCount >= TREEIFY_THRESHOLD - 1)
                        treeifyBin(tab, hash);
                    break;
                }
                
                // Found existing key
                if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k))))
                    break;
                
                p = e;
            }
        }
        
        // 5. Replace old value if key exists
        if (e != null) {
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            return oldValue;
        }
    }
    
    // 6. Increment size and check if resize needed
    ++size;
    if (size > threshold)
        resize();
    
    return null;
}
```

**put() Steps:**
1. Calculate hash: `hash(key)`
2. Find bucket: `index = hash & (capacity - 1)`
3. If bucket empty: Create new node
4. If collision: Check existing nodes
   - Same key? Update value
   - Tree node? Insert in tree
   - Linked list? Append or find
5. If size > threshold: Resize (double capacity)

---

## üîç get() Operation Flow

```java
public V get(Object key) {
    Node<K,V> e;
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}

final Node<K,V> getNode(int hash, Object key) {
    Node<K,V>[] tab;
    Node<K,V> first, e;
    int n;
    K k;
    
    // 1. Table not empty and bucket not empty
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (first = tab[(n - 1) & hash]) != null) {
        
        // 2. Check first node (optimization)
        if (first.hash == hash &&
            ((k = first.key) == key || (key != null && key.equals(k))))
            return first;
        
        // 3. Check rest of bucket
        if ((e = first.next) != null) {
            // 3a. If tree, search tree
            if (first instanceof TreeNode)
                return ((TreeNode<K,V>)first).getTreeNode(hash, key);
            
            // 3b. Traverse linked list
            do {
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    
    return null;
}
```

**get() Steps:**
1. Calculate hash: `hash(key)`
2. Find bucket: `index = hash & (capacity - 1)`
3. Check first node (fast path)
4. If collision:
   - Tree? Search tree (O(log n))
   - List? Search list (O(n))

---

## üìà Resize Operation

```java
final Node<K,V>[] resize() {
    Node<K,V>[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    
    // Calculate new capacity (double)
    if (oldCap > 0) {
        if (oldCap >= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                 oldCap >= DEFAULT_INITIAL_CAPACITY)
            newThr = oldThr << 1; // Double threshold
    }
    
    // Create new table
    Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab;
    
    // Rehash all entries
    if (oldTab != null) {
        for (int j = 0; j < oldCap; ++j) {
            Node<K,V> e;
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                
                if (e.next == null)
                    // Single node, rehash
                    newTab[e.hash & (newCap - 1)] = e;
                else if (e instanceof TreeNode)
                    // Split tree
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                else {
                    // Rehash linked list
                    // Nodes go to either same index or index + oldCap
                    Node<K,V> loHead = null, loTail = null;
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    
                    do {
                        next = e.next;
                        // Check if bit is 0 or 1
                        if ((e.hash & oldCap) == 0) {
                            // Stay at same index
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        else {
                            // Move to index + oldCap
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    
    return newTab;
}
```

**Resize Process:**
1. **Double capacity** (16 ‚Üí 32 ‚Üí 64 ‚Üí ...)
2. **Create new array**
3. **Rehash all entries** (recalculate index)
4. **Update threshold** (newCapacity √ó loadFactor)

**Clever Optimization:**
- Nodes stay at same index OR move to `index + oldCapacity`
- Uses bit checking: `(hash & oldCap) == 0`

---

## üå≥ Treeification (Java 8+)

**When collision chain gets too long (‚â•8 nodes), convert to Red-Black Tree:**

```java
static final int TREEIFY_THRESHOLD = 8;
static final int UNTREEIFY_THRESHOLD = 6;
static final int MIN_TREEIFY_CAPACITY = 64;

// Treeify only if capacity >= 64
// Otherwise, just resize
final void treeifyBin(Node<K,V>[] tab, int hash) {
    int n, index;
    Node<K,V> e;
    
    if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
        resize();
    else if ((e = tab[index = (n - 1) & hash]) != null) {
        // Convert linked list to red-black tree
        TreeNode<K,V> hd = null, tl = null;
        do {
            TreeNode<K,V> p = replacementTreeNode(e, null);
            if (tl == null)
                hd = p;
            else {
                p.prev = tl;
                tl.next = p;
            }
            tl = p;
        } while ((e = e.next) != null);
        
        if ((tab[index] = hd) != null)
            hd.treeify(tab);
    }
}
```

**Why Treeification?**
- **O(n) ‚Üí O(log n)** for collision chain
- Improves worst-case from O(n) to O(log n)
- Only when chain ‚â• 8 and capacity ‚â• 64

**Bucket States:**
- **Empty**: null
- **Single node**: One Node
- **Linked list**: 2-7 nodes
- **Red-Black Tree**: ‚â•8 nodes (if capacity ‚â• 64)

---

## üí° Collision Handling Evolution

```
Java 7 and earlier:
Array ‚Üí Linked List (O(n) worst case)

Java 8+:
Array ‚Üí Linked List (< 8 nodes)
      ‚Üí Red-Black Tree (‚â• 8 nodes, capacity ‚â• 64)
      
Worst case: O(n) ‚Üí O(log n)
```

---

## üéØ Hash Code Best Practices

```java
// ‚ùå Bad hashCode - all collisions!
class BadKey {
    String name;
    
    @Override
    public int hashCode() {
        return 1;  // All objects have same hash!
    }
}

// ‚úÖ Good hashCode - distributed
class GoodKey {
    String name;
    int age;
    
    @Override
    public int hashCode() {
        return Objects.hash(name, age);
    }
    
    @Override
    public boolean equals(Object obj) {
        if (this == obj) return true;
        if (obj == null || getClass() != obj.getClass()) return false;
        GoodKey other = (GoodKey) obj;
        return age == other.age && Objects.equals(name, other.name);
    }
}

// Record (Java 14+) - auto-generated equals/hashCode
record Person(String name, int age) {}
```

**hashCode() Rules:**
1. **Consistent**: Same object ‚Üí same hash (unless modified)
2. **Equal objects**: `a.equals(b)` ‚Üí `a.hashCode() == b.hashCode()`
3. **Distributed**: Different objects ‚Üí different hashes (ideally)

---

## üìä Performance Analysis

### Best Case (No Collisions)
```
put():  O(1)
get():  O(1)
remove(): O(1)

All operations hit correct bucket directly.
```

### Average Case (Few Collisions)
```
put():  O(1) amortized
get():  O(1)
remove(): O(1)

Occasional collisions handled by short lists.
```

### Worst Case (All Collisions)
```
Java 7: O(n) - all in one linked list
Java 8+: O(log n) - tree after 8 nodes

With good hash function, very rare.
```

---

## üéØ Capacity and Performance

```java
// Scenario 1: Small initial capacity
Map<String, Integer> map1 = new HashMap<>(2);
for (int i = 0; i < 1000; i++) {
    map1.put("key" + i, i);  // Many resizes (slow)
}

// Scenario 2: Appropriate initial capacity
Map<String, Integer> map2 = new HashMap<>(1334); // 1000 / 0.75 + 1
for (int i = 0; i < 1000; i++) {
    map2.put("key" + i, i);  // No resizes (fast)
}

// Scenario 3: Too large initial capacity
Map<String, Integer> map3 = new HashMap<>(10000);
for (int i = 0; i < 10; i++) {
    map3.put("key" + i, i);  // Wastes memory
}
```

**Formula for Initial Capacity:**
```
initialCapacity = (expectedSize / loadFactor) + 1
```

---

## üÜö Load Factor Impact

```
Load Factor | Collisions | Memory | Speed
------------|------------|--------|-------
   0.50     |    Low     |  High  |  Fast
   0.75     |  Medium    | Medium | Medium (Default)
   0.90     |    High    |  Low   |  Slow
   1.00     |  Very High |  Low   | Very Slow
```

**Lower Load Factor:**
- ‚úÖ Fewer collisions
- ‚úÖ Faster lookups
- ‚ùå More memory

**Higher Load Factor:**
- ‚ùå More collisions
- ‚ùå Slower lookups
- ‚úÖ Less memory

**Default 0.75:** Good balance between time and space.

---

## üéì Interview Questions

**Q: How does HashMap work internally?**
A: Uses array of buckets, hash function to find index, linked list/tree for collisions.

**Q: What is hash collision?**
A: When two different keys have same hash code or map to same bucket.

**Q: How are collisions handled?**
A: Linked list (< 8 nodes) or Red-Black Tree (‚â• 8 nodes, Java 8+).

**Q: Why power of 2 capacity?**
A: Allows fast index calculation using `hash & (capacity - 1)` instead of modulo.

**Q: What is load factor?**
A: Threshold (0.75 default) that triggers resize when `size > capacity √ó loadFactor`.

**Q: What happens during resize?**
A: Capacity doubles, all entries rehashed to new buckets.

**Q: Why treeify at 8 nodes?**
A: Improves worst-case from O(n) to O(log n) for long collision chains.

**Q: What is the time complexity of HashMap?**
A: O(1) average for get/put, O(log n) worst case (Java 8+ with tree).

**Q: Why override equals() and hashCode()?**
A: HashMap uses hash to find bucket, equals to find exact key.

---

## üìö Summary

- **Array + Linked List/Tree**: Core structure
- **Hash function**: `hash(key) ^ (hash >>> 16)`
- **Index calculation**: `hash & (capacity - 1)`
- **Collision handling**: Linked list ‚Üí Red-Black Tree (‚â•8 nodes)
- **Resize**: Doubles capacity when `size > threshold`
- **Load factor**: 0.75 default, balances time vs space
- **Treeification**: Improves worst-case to O(log n)
- **Power of 2 capacity**: Enables fast bitwise index calculation
- **equals() and hashCode()**: Must override for custom keys
- Understanding internals helps optimize performance and avoid pitfalls
