# Kafka Templates - Complete Guide

---

## 1. Introduction to KafkaTemplate

`KafkaTemplate` is Spring Kafka's high-level abstraction for producing messages. It wraps the native Kafka producer and provides a simplified, Spring-friendly API for sending messages to Kafka topics.

### Key Features
- **Simplified API** for sending messages
- **Asynchronous and synchronous** sending
- **Transaction support**
- **Callbacks and futures** for result handling
- **Routing templates** for different message types
- **Metrics and monitoring** integration

---

## 2. Basic KafkaTemplate Usage

### 2.1. Autowiring KafkaTemplate

```java
@Service
public class MessageProducerService {
    
    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;
    
    public void sendMessage(String topic, String message) {
        kafkaTemplate.send(topic, message);
    }
}
```

### 2.2. Send Methods

```java
// Simple send - fire and forget
kafkaTemplate.send("topic-name", "message");

// Send with key
kafkaTemplate.send("topic-name", "key", "message");

// Send to specific partition
kafkaTemplate.send("topic-name", partition, "key", "message");

// Send ProducerRecord
ProducerRecord<String, String> record = new ProducerRecord<>("topic", "key", "message");
kafkaTemplate.send(record);

// Send with Message<?> wrapper
Message<String> message = MessageBuilder
    .withPayload("payload")
    .setHeader(KafkaHeaders.TOPIC, "topic-name")
    .setHeader(KafkaHeaders.KEY, "key")
    .build();
kafkaTemplate.send(message);
```

---

## 3. Asynchronous Sending with Callbacks

### 3.1. CompletableFuture

```java
@Service
public class AsyncProducer {
    
    @Autowired
    private KafkaTemplate<String, Order> kafkaTemplate;
    
    public void sendOrder(Order order) {
        CompletableFuture<SendResult<String, Order>> future = 
            kafkaTemplate.send("orders", order.getId(), order);
        
        future.whenComplete((result, ex) -> {
            if (ex == null) {
                RecordMetadata metadata = result.getRecordMetadata();
                log.info("Sent message=[{}] with offset=[{}] to partition=[{}]", 
                    order, metadata.offset(), metadata.partition());
            } else {
                log.error("Unable to send message=[{}] due to: {}", order, ex.getMessage());
            }
        });
    }
}
```

### 3.2. Success and Failure Callbacks

```java
public void sendWithCallbacks(Order order) {
    CompletableFuture<SendResult<String, Order>> future = 
        kafkaTemplate.send("orders", order.getId(), order);
    
    future.thenAccept(result -> {
        log.info("Success: offset={}, partition={}", 
            result.getRecordMetadata().offset(),
            result.getRecordMetadata().partition());
    }).exceptionally(ex -> {
        log.error("Failure: {}", ex.getMessage());
        return null;
    });
}
```

### 3.3. Chaining Operations

```java
public void sendWithChaining(Order order) {
    kafkaTemplate.send("orders", order)
        .thenApply(result -> {
            log.info("Order sent successfully");
            return result;
        })
        .thenCompose(result -> {
            // Send confirmation
            return kafkaTemplate.send("confirmations", createConfirmation(order));
        })
        .exceptionally(ex -> {
            log.error("Pipeline failed", ex);
            return null;
        });
}
```

---

## 4. Synchronous Sending

### 4.1. Blocking Send

```java
public void sendSync(Order order) {
    try {
        SendResult<String, Order> result = 
            kafkaTemplate.send("orders", order.getId(), order)
                .get(10, TimeUnit.SECONDS);
        
        log.info("Message sent: offset={}", result.getRecordMetadata().offset());
    } catch (InterruptedException | ExecutionException | TimeoutException e) {
        log.error("Failed to send message", e);
        throw new RuntimeException("Kafka send failed", e);
    }
}
```

### 4.2. Use Cases for Synchronous Send
- Critical operations requiring confirmation
- Transaction boundaries
- Testing and debugging
- Low-throughput scenarios

⚠️ **Warning:** Synchronous sends reduce throughput significantly.

---

## 5. Custom KafkaTemplate Configuration

### 5.1. Bean Configuration

```java
@Configuration
public class KafkaTemplateConfig {
    
    @Bean
    public ProducerFactory<String, Order> orderProducerFactory() {
        Map<String, Object> config = new HashMap<>();
        config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
        config.put(ProducerConfig.ACKS_CONFIG, "all");
        config.put(ProducerConfig.RETRIES_CONFIG, 3);
        config.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);
        config.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "snappy");
        
        return new DefaultKafkaProducerFactory<>(config);
    }
    
    @Bean
    public KafkaTemplate<String, Order> orderKafkaTemplate() {
        return new KafkaTemplate<>(orderProducerFactory());
    }
}
```

### 5.2. Multiple KafkaTemplates

```java
@Configuration
public class MultiTemplateConfig {
    
    @Bean
    public KafkaTemplate<String, Order> orderTemplate() {
        return new KafkaTemplate<>(orderProducerFactory());
    }
    
    @Bean
    public KafkaTemplate<String, Payment> paymentTemplate() {
        return new KafkaTemplate<>(paymentProducerFactory());
    }
    
    @Bean
    public KafkaTemplate<String, String> stringTemplate() {
        return new KafkaTemplate<>(stringProducerFactory());
    }
}
```

Usage:
```java
@Service
public class MultiProducer {
    
    @Autowired
    @Qualifier("orderTemplate")
    private KafkaTemplate<String, Order> orderTemplate;
    
    @Autowired
    @Qualifier("paymentTemplate")
    private KafkaTemplate<String, Payment> paymentTemplate;
}
```

---

## 6. Default Topic Configuration

### 6.1. Set Default Topic

```java
@Bean
public KafkaTemplate<String, Order> kafkaTemplate() {
    KafkaTemplate<String, Order> template = new KafkaTemplate<>(producerFactory());
    template.setDefaultTopic("default-orders");
    return template;
}
```

Usage:
```java
// Sends to "default-orders"
kafkaTemplate.sendDefault("key", order);
kafkaTemplate.sendDefault(partition, "key", order);
```

---

## 7. Routing Template

### 7.1. Custom Routing Logic

```java
@Bean
public RoutingKafkaTemplate routingTemplate() {
    Map<Pattern, ProducerFactory<Object, Object>> map = new LinkedHashMap<>();
    
    // Route orders to order-specific producer
    map.put(Pattern.compile("order-.*"), orderProducerFactory());
    
    // Route payments to payment-specific producer
    map.put(Pattern.compile("payment-.*"), paymentProducerFactory());
    
    // Default producer for all other topics
    map.put(Pattern.compile(".*"), defaultProducerFactory());
    
    return new RoutingKafkaTemplate(map);
}
```

Usage:
```java
@Autowired
private RoutingKafkaTemplate routingTemplate;

public void send() {
    routingTemplate.send("order-events", order);    // Uses orderProducerFactory
    routingTemplate.send("payment-events", payment); // Uses paymentProducerFactory
    routingTemplate.send("logs", logMessage);        // Uses defaultProducerFactory
}
```

---

## 8. Headers and Metadata

### 8.1. Adding Headers

```java
public void sendWithHeaders(Order order) {
    ProducerRecord<String, Order> record = 
        new ProducerRecord<>("orders", order.getId(), order);
    
    // Add custom headers
    record.headers().add("source", "order-service".getBytes());
    record.headers().add("version", "1.0".getBytes());
    record.headers().add("timestamp", String.valueOf(System.currentTimeMillis()).getBytes());
    record.headers().add("correlation-id", UUID.randomUUID().toString().getBytes());
    
    kafkaTemplate.send(record);
}
```

### 8.2. Using Message Builder

```java
public void sendWithMessageBuilder(Order order) {
    Message<Order> message = MessageBuilder
        .withPayload(order)
        .setHeader(KafkaHeaders.TOPIC, "orders")
        .setHeader(KafkaHeaders.KEY, order.getId())
        .setHeader(KafkaHeaders.PARTITION, 0)
        .setHeader("source", "order-service")
        .setHeader("correlation-id", UUID.randomUUID().toString())
        .build();
    
    kafkaTemplate.send(message);
}
```

---

## 9. Transactional KafkaTemplate

### 9.1. Configuration

```yaml
spring:
  kafka:
    producer:
      transaction-id-prefix: tx-
```

```java
@Configuration
@EnableTransactionManagement
public class TransactionalKafkaConfig {
    
    @Bean
    public ProducerFactory<String, Order> producerFactory() {
        DefaultKafkaProducerFactory<String, Order> factory = 
            new DefaultKafkaProducerFactory<>(producerConfigs());
        factory.setTransactionIdPrefix("order-tx-");
        return factory;
    }
    
    @Bean
    public KafkaTemplate<String, Order> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }
    
    @Bean
    public KafkaTransactionManager kafkaTransactionManager() {
        return new KafkaTransactionManager(producerFactory());
    }
}
```

### 9.2. Using @Transactional

```java
@Service
public class TransactionalService {
    
    @Autowired
    private KafkaTemplate<String, Order> kafkaTemplate;
    
    @Transactional
    public void processOrder(Order order) {
        kafkaTemplate.send("orders", order);
        kafkaTemplate.send("audit", createAudit(order));
        // Both sends committed atomically
        // If exception occurs, both are rolled back
    }
}
```

### 9.3. Programmatic Transactions

```java
public void executeInTransaction(Order order) {
    kafkaTemplate.executeInTransaction(template -> {
        template.send("orders", order);
        template.send("notifications", createNotification(order));
        return true;
    });
}
```

### 9.4. Transaction with Database

```java
@Service
public class OrderService {
    
    @Autowired
    private KafkaTemplate<String, Order> kafkaTemplate;
    
    @Autowired
    private OrderRepository orderRepository;
    
    @Transactional("kafkaTransactionManager")
    public void saveAndPublish(Order order) {
        // Save to database
        orderRepository.save(order);
        
        // Publish to Kafka
        kafkaTemplate.send("orders", order);
        
        // Both committed together or rolled back
    }
}
```

---

## 10. Message Conversion

### 10.1. String to JSON

```java
@Bean
public ProducerFactory<String, Object> producerFactory() {
    Map<String, Object> config = new HashMap<>();
    config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
    config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
    config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
    config.put(JsonSerializer.ADD_TYPE_INFO_HEADERS, false);
    
    return new DefaultKafkaProducerFactory<>(config);
}
```

### 10.2. Custom Message Converter

```java
@Bean
public KafkaTemplate<String, Order> kafkaTemplate() {
    KafkaTemplate<String, Order> template = new KafkaTemplate<>(producerFactory());
    template.setMessageConverter(new StringJsonMessageConverter());
    return template;
}
```

---

## 11. Producer Interceptors

### 11.1. Custom Interceptor

```java
public class AuditProducerInterceptor implements ProducerInterceptor<String, Object> {
    
    @Override
    public ProducerRecord<String, Object> onSend(ProducerRecord<String, Object> record) {
        // Add audit header
        record.headers().add("sent-at", String.valueOf(System.currentTimeMillis()).getBytes());
        record.headers().add("sent-by", "order-service".getBytes());
        
        log.info("Sending message to topic: {}", record.topic());
        return record;
    }
    
    @Override
    public void onAcknowledgement(RecordMetadata metadata, Exception exception) {
        if (exception == null) {
            log.info("Message acknowledged: offset={}", metadata.offset());
        } else {
            log.error("Send failed", exception);
        }
    }
    
    @Override
    public void close() {}
    
    @Override
    public void configure(Map<String, ?> configs) {}
}
```

### 11.2. Register Interceptor

```java
@Bean
public ProducerFactory<String, Object> producerFactory() {
    Map<String, Object> config = new HashMap<>();
    // ... other configs
    config.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, 
        AuditProducerInterceptor.class.getName());
    
    return new DefaultKafkaProducerFactory<>(config);
}
```

---

## 12. Error Handling

### 12.1. Producer Listener

```java
@Bean
public KafkaTemplate<String, Order> kafkaTemplate() {
    KafkaTemplate<String, Order> template = new KafkaTemplate<>(producerFactory());
    
    template.setProducerListener(new ProducerListener<String, Order>() {
        @Override
        public void onSuccess(ProducerRecord<String, Order> record, 
                            RecordMetadata metadata) {
            log.info("Message sent successfully: topic={}, offset={}", 
                metadata.topic(), metadata.offset());
        }
        
        @Override
        public void onError(ProducerRecord<String, Order> record, 
                           RecordMetadata metadata, Exception exception) {
            log.error("Failed to send message: {}", record, exception);
        }
    });
    
    return template;
}
```

### 12.2. Retry Logic

```java
public void sendWithRetry(Order order) {
    int maxRetries = 3;
    int attempt = 0;
    
    while (attempt < maxRetries) {
        try {
            kafkaTemplate.send("orders", order).get();
            log.info("Message sent successfully");
            return;
        } catch (Exception e) {
            attempt++;
            log.warn("Attempt {} failed", attempt, e);
            
            if (attempt >= maxRetries) {
                log.error("All retry attempts exhausted");
                throw new RuntimeException("Failed to send message", e);
            }
            
            try {
                Thread.sleep(1000 * attempt); // Exponential backoff
            } catch (InterruptedException ie) {
                Thread.currentThread().interrupt();
            }
        }
    }
}
```

---

## 13. Metrics and Monitoring

### 13.1. Producer Metrics

```java
@Component
public class KafkaMetrics {
    
    @Autowired
    private KafkaTemplate<String, Order> kafkaTemplate;
    
    public Map<MetricName, ? extends Metric> getProducerMetrics() {
        return kafkaTemplate.metrics();
    }
    
    public void logMetrics() {
        kafkaTemplate.metrics().forEach((name, metric) -> {
            log.info("Metric: {} = {}", name.name(), metric.metricValue());
        });
    }
}
```

### 13.2. Key Metrics to Monitor
- `record-send-rate`: Messages sent per second
- `record-error-rate`: Failed sends per second
- `request-latency-avg`: Average request latency
- `batch-size-avg`: Average batch size
- `buffer-available-bytes`: Available buffer memory

---

## 14. Testing KafkaTemplate

### 14.1. Embedded Kafka Test

```java
@SpringBootTest
@EmbeddedKafka(partitions = 1, topics = {"test-topic"})
public class KafkaTemplateTest {
    
    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;
    
    @Autowired
    private EmbeddedKafkaBroker embeddedKafka;
    
    @Test
    public void testSend() throws Exception {
        kafkaTemplate.send("test-topic", "test-message").get();
        // Assert message received
    }
}
```

### 14.2. Mock KafkaTemplate

```java
@ExtendWith(MockitoExtension.class)
public class ProducerServiceTest {
    
    @Mock
    private KafkaTemplate<String, Order> kafkaTemplate;
    
    @InjectMocks
    private OrderProducerService producerService;
    
    @Test
    public void testSendOrder() {
        Order order = new Order("123", "Product");
        
        when(kafkaTemplate.send(anyString(), any(Order.class)))
            .thenReturn(CompletableFuture.completedFuture(null));
        
        producerService.sendOrder(order);
        
        verify(kafkaTemplate).send("orders", order);
    }
}
```

---

## 15. Best Practices

1. **Use async send by default** for better throughput
2. **Handle callbacks** to detect failures
3. **Enable idempotence** for exactly-once semantics
4. **Use transactions** for atomic multi-message operations
5. **Set appropriate timeouts** to avoid indefinite blocking
6. **Configure compression** (snappy, lz4) for large messages
7. **Batch messages** with linger.ms for efficiency
8. **Monitor producer metrics** for performance issues
9. **Use routing template** for multiple message types
10. **Add correlation IDs** in headers for tracing

---

## 16. Common Pitfalls

1. **Blocking on sync send** in high-throughput scenarios
2. **Ignoring send failures** when using async
3. **Not handling serialization errors**
4. **Incorrect transaction configuration**
5. **Memory issues** from unbounded message buffering
6. **Not monitoring producer lag** and metrics

---

## 17. Interview Questions

**Q1: What is KafkaTemplate?**
**A:** Spring abstraction for producing messages to Kafka topics with simplified API.

**Q2: Async vs sync send?**
**A:** Async returns CompletableFuture (non-blocking). Sync blocks until acknowledgment.

**Q3: How to handle send failures?**
**A:** Use callbacks on CompletableFuture: whenComplete, thenAccept, exceptionally.

**Q4: What is RoutingKafkaTemplate?**
**A:** Template that routes messages to different ProducerFactories based on topic patterns.

**Q5: How to send transactional messages?**
**A:** Configure transaction-id-prefix, use @Transactional or executeInTransaction.

**Q6: How to add custom headers?**
**A:** Use ProducerRecord.headers().add() or MessageBuilder.setHeader().

**Q7: What is ProducerListener?**
**A:** Callback interface for producer success/failure events.

**Q8: How to send to specific partition?**
**A:** Use kafkaTemplate.send(topic, partition, key, value).

**Q9: How to configure multiple templates?**
**A:** Create multiple beans with different ProducerFactories and use @Qualifier.

**Q10: What is default topic?**
**A:** Topic set on template for use with sendDefault() method.

**Q11: How to monitor producer performance?**
**A:** Use kafkaTemplate.metrics() to access Kafka producer metrics.

**Q12: What is message converter?**
**A:** Converts message payload to/from different formats (JSON, Avro, etc.).

**Q13: How to implement retry logic?**
**A:** Configure retries in producer config or implement manual retry with exponential backoff.

**Q14: What is producer interceptor?**
**A:** Allows modification of records before send and callback after acknowledgment.

**Q15: How to test KafkaTemplate?**
**A:** Use @EmbeddedKafka for integration tests or mock for unit tests.

**Q16: What is sendDefault()?**
**A:** Sends message to the default topic configured on the template.

**Q17: How to ensure exactly-once?**
**A:** Enable idempotence + use transactions + read_committed on consumer.

**Q18: What is linger.ms?**
**A:** Time producer waits to batch more messages. Trades latency for throughput.

**Q19: How to send multiple message types?**
**A:** Use RoutingKafkaTemplate or multiple typed KafkaTemplates.

**Q20: What is flush()?**
**A:** Forces all buffered messages to be sent immediately. Blocks until complete.

---

## 18. Summary

KafkaTemplate simplifies Kafka message production with Spring-friendly APIs, comprehensive configuration options, transaction support, and excellent integration with Spring ecosystem. Mastering async operations, error handling, and performance tuning ensures robust, high-throughput messaging applications.

---

**Next:** Message Listeners →
