# ‚ö° Parallel Streams

## üìñ Overview

**Parallel streams** enable automatic parallel processing of data by dividing the stream into multiple chunks, processing them on different threads, and combining the results.

**Key Points:**
- Built on Fork/Join framework
- Uses common ForkJoinPool
- Easy parallelization with `.parallelStream()`
- Not always faster - overhead exists

---

## üíª Creating Parallel Streams

### Method 1: parallelStream()
```java
List<Integer> numbers = Arrays.asList(1, 2, 3, 4, 5);

// Parallel stream from collection
numbers.parallelStream()
    .forEach(System.out::println);
```

### Method 2: parallel()
```java
// Convert sequential to parallel
Stream<Integer> sequential = numbers.stream();
Stream<Integer> parallel = sequential.parallel();

// Check if parallel
boolean isParallel = parallel.isParallel();  // true
```

### Method 3: Convert Back to Sequential
```java
Stream<Integer> sequential = parallel.sequential();
```

---

## üîÑ Parallel vs Sequential

### Sequential Processing
```java
long start = System.currentTimeMillis();

List<Integer> result = IntStream.range(1, 1000)
    .boxed()
    .map(n -> {
        // Simulate heavy computation
        try { Thread.sleep(1); } catch (InterruptedException e) {}
        return n * 2;
    })
    .collect(Collectors.toList());

long end = System.currentTimeMillis();
System.out.println("Sequential: " + (end - start) + "ms");
```

### Parallel Processing
```java
long start = System.currentTimeMillis();

List<Integer> result = IntStream.range(1, 1000)
    .parallel()
    .boxed()
    .map(n -> {
        // Simulate heavy computation
        try { Thread.sleep(1); } catch (InterruptedException e) {}
        return n * 2;
    })
    .collect(Collectors.toList());

long end = System.currentTimeMillis();
System.out.println("Parallel: " + (end - start) + "ms");
```

---

## üìä When to Use Parallel Streams

### ‚úÖ Good Use Cases

**1. Large Data Sets**
```java
// Processing millions of records
List<Data> largeDataset = getMillionsOfRecords();

List<Result> results = largeDataset.parallelStream()
    .filter(data -> data.isValid())
    .map(this::processData)
    .collect(Collectors.toList());
```

**2. CPU-Intensive Operations**
```java
// Heavy computations
List<Integer> primes = IntStream.range(1, 100000)
    .parallel()
    .filter(this::isPrime)
    .boxed()
    .collect(Collectors.toList());
```

**3. Independent Operations**
```java
// No dependencies between elements
numbers.parallelStream()
    .map(n -> n * n)
    .collect(Collectors.toList());
```

### ‚ùå Bad Use Cases

**1. Small Data Sets**
```java
// Overhead > benefit
List<Integer> small = Arrays.asList(1, 2, 3, 4, 5);
small.parallelStream()  // NOT worth it
    .map(n -> n * 2)
    .collect(Collectors.toList());
```

**2. Order-Dependent Operations**
```java
// Order matters
List<String> ordered = list.parallelStream()
    .sorted()  // Defeats parallelism
    .collect(Collectors.toList());
```

**3. Shared Mutable State**
```java
// WRONG - race condition
List<Integer> results = new ArrayList<>();
numbers.parallelStream()
    .forEach(n -> results.add(n * 2));  // NOT thread-safe!

// CORRECT - use collect
List<Integer> results = numbers.parallelStream()
    .map(n -> n * 2)
    .collect(Collectors.toList());
```

---

## ‚ö†Ô∏è Thread Safety Issues

### Problem: Shared Mutable State
```java
// UNSAFE!
int[] sum = {0};
IntStream.range(1, 100)
    .parallel()
    .forEach(n -> sum[0] += n);  // Race condition!

// SAFE - use reduce
int sum = IntStream.range(1, 100)
    .parallel()
    .sum();
```

### Problem: Non-Thread-Safe Collections
```java
// UNSAFE!
List<Integer> list = new ArrayList<>();
IntStream.range(1, 100)
    .parallel()
    .forEach(list::add);  // ArrayList is not thread-safe!

// SAFE - use collect
List<Integer> list = IntStream.range(1, 100)
    .parallel()
    .boxed()
    .collect(Collectors.toList());
```

---

## üéØ ForkJoinPool Configuration

### Default Pool
```java
// Uses common ForkJoinPool
// Pool size = number of available processors
int poolSize = Runtime.getRuntime().availableProcessors();
```

### Custom Pool Size
```java
// Set via system property (affects all parallel streams)
System.setProperty("java.util.concurrent.ForkJoinPool.common.parallelism", "4");
```

### Custom ForkJoinPool
```java
// Use specific pool
ForkJoinPool customPool = new ForkJoinPool(4);

try {
    List<Integer> result = customPool.submit(() ->
        numbers.parallelStream()
            .map(n -> n * 2)
            .collect(Collectors.toList())
    ).get();
} catch (InterruptedException | ExecutionException e) {
    e.printStackTrace();
}
```

---

## üîç Parallel Stream Operations

### forEach vs forEachOrdered
```java
List<Integer> numbers = Arrays.asList(1, 2, 3, 4, 5);

// Order not guaranteed
numbers.parallelStream()
    .forEach(System.out::println);

// Order maintained (but slower)
numbers.parallelStream()
    .forEachOrdered(System.out::println);
```

### Parallel Reduction
```java
// Sum
int sum = numbers.parallelStream()
    .reduce(0, Integer::sum);

// Custom combiner for parallel processing
int result = numbers.parallelStream()
    .reduce(
        0,                          // identity
        (a, b) -> a + b,           // accumulator
        (a, b) -> a + b            // combiner (for parallel)
    );
```

### Parallel Collectors
```java
// Thread-safe collection
Map<Integer, List<Integer>> grouped = numbers.parallelStream()
    .collect(Collectors.groupingByConcurrent(n -> n % 2));
```

---

## üìä Performance Comparison

```java
public class ParallelPerformanceTest {
    public static void main(String[] args) {
        List<Integer> numbers = IntStream.range(1, 10_000_000)
            .boxed()
            .collect(Collectors.toList());
        
        // Sequential
        long start1 = System.nanoTime();
        long count1 = numbers.stream()
            .filter(n -> n % 2 == 0)
            .count();
        long end1 = System.nanoTime();
        System.out.println("Sequential: " + (end1 - start1) / 1_000_000 + "ms");
        
        // Parallel
        long start2 = System.nanoTime();
        long count2 = numbers.parallelStream()
            .filter(n -> n % 2 == 0)
            .count();
        long end2 = System.nanoTime();
        System.out.println("Parallel: " + (end2 - start2) / 1_000_000 + "ms");
    }
}
```

---

## ‚ö° Best Practices

| Practice | Description |
|----------|-------------|
| ‚úÖ Use for large datasets | > 10,000 elements typically |
| ‚úÖ CPU-intensive operations | Heavy computations benefit most |
| ‚úÖ Stateless operations | No shared mutable state |
| ‚úÖ Use collect() for results | Thread-safe collection |
| ‚úÖ Measure performance | Always benchmark |
| ‚ùå Avoid for small data | Overhead > benefit |
| ‚ùå Don't modify shared state | Race conditions |
| ‚ùå Avoid ordering operations | sorted() defeats parallelism |
| ‚ùå Don't use non-thread-safe collections | Use collectors instead |

---

## üéØ Performance Guidelines

| Factor | Impact | Recommendation |
|--------|--------|----------------|
| **Data size** | Small = overhead | Use sequential for < 10K elements |
| **Operation cost** | Cheap ops = overhead | Use parallel for CPU-intensive |
| **Data structure** | ArrayList > LinkedList | ArrayList better for splitting |
| **Stateless** | Better parallelism | Avoid shared mutable state |
| **Ordering** | Overhead | Use unordered() if possible |

---

## üîó Related Topics

- [Stream Performance](07.%20Stream%20Performance.md)
- [Terminal Operations](04.%20Terminal%20Operations.md)
- [Collectors](05.%20Collectors.md)

---

## üí° Key Takeaways

- Parallel streams use Fork/Join framework
- Easy to use: `.parallelStream()` or `.parallel()`
- Not always faster - overhead exists
- Best for large datasets with CPU-intensive ops
- Avoid shared mutable state
- Use collect() for thread-safe results
- forEachOrdered() maintains order but slower
- Measure performance before using
- Default pool size = CPU cores
- Consider custom ForkJoinPool for control
