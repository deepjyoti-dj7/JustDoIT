# Best Practices

## Table of Contents
- [General Principles](#general-principles)
- [Worker Management](#worker-management)
- [Error Handling](#error-handling)
- [Testing Concurrent Code](#testing-concurrent-code)
- [Debugging Strategies](#debugging-strategies)
- [Security Considerations](#security-considerations)
- [Design Patterns](#design-patterns)
- [Common Anti-Patterns](#common-anti-patterns)

---

## General Principles

### 1. Start Simple, Then Optimize

```javascript
// ❌ Don't start with complex concurrency
const workers = Array.from({ length: 100 }, () => new Worker('...'))
const sharedBuffer = new SharedArrayBuffer(...)
// Complex locking logic...

// ✅ Start with simple async
async function processData(data) {
  return await fetch('/api/process', {
    method: 'POST',
    body: JSON.stringify(data)
  })
}

// ✅ Add concurrency when needed
const pool = new WorkerPool('process.js', 4)
const results = await Promise.all(
  chunks.map(chunk => pool.execute(chunk))
)
```

### 2. Measure Before Optimizing

```javascript
// ✅ Profile first
console.time('sequential')
const result1 = await sequentialProcess(data)
console.timeEnd('sequential')

console.time('parallel')
const result2 = await parallelProcess(data)
console.timeEnd('parallel')

// Only use parallel if it's actually faster!
```

### 3. Match Concurrency to Workload

```javascript
// ❌ Wrong: Too many workers for small task
const workers = 100
const smallData = [1, 2, 3]

// ✅ Right: Scale workers to data and cores
const workerCount = Math.min(
  navigator.hardwareConcurrency || 4,
  Math.ceil(data.length / 1000)
)
```

---

## Worker Management

### Pool Pattern:

```javascript
// ✅ Always use worker pools
class WorkerPool {
  constructor(script, size) {
    this.workers = Array.from({ length: size }, () => ({
      worker: new Worker(script),
      busy: false
    }))
  }
  
  async execute(data) {
    const worker = await this.getAvailableWorker()
    
    try {
      return await this.runTask(worker, data)
    } finally {
      worker.busy = false
    }
  }
  
  async getAvailableWorker() {
    while (true) {
      const worker = this.workers.find(w => !w.busy)
      if (worker) {
        worker.busy = true
        return worker
      }
      await new Promise(resolve => setTimeout(resolve, 10))
    }
  }
  
  runTask(workerInfo, data) {
    return new Promise((resolve, reject) => {
      const { worker } = workerInfo
      
      worker.onmessage = (e) => resolve(e.data)
      worker.onerror = (e) => reject(e)
      
      worker.postMessage(data)
    })
  }
  
  terminate() {
    this.workers.forEach(w => w.worker.terminate())
  }
}
```

### Lifecycle Management:

```javascript
// ✅ Clean up workers
class ManagedWorkerPool extends WorkerPool {
  constructor(script, size) {
    super(script, size)
    
    // Cleanup on page unload
    window.addEventListener('beforeunload', () => {
      this.terminate()
    })
  }
  
  terminate() {
    super.terminate()
    console.log('Workers terminated')
  }
}

// ✅ React cleanup
function useWorkerPool(script, size) {
  const poolRef = useRef(null)
  
  useEffect(() => {
    poolRef.current = new WorkerPool(script, size)
    
    return () => {
      poolRef.current?.terminate()
    }
  }, [script, size])
  
  return poolRef.current
}
```

---

## Error Handling

### Comprehensive Error Handling:

```javascript
class RobustWorkerPool {
  async execute(data) {
    let lastError
    
    for (let attempt = 0; attempt < 3; attempt++) {
      try {
        return await this.executeOnce(data)
      } catch (error) {
        lastError = error
        console.warn(`Attempt ${attempt + 1} failed:`, error)
        
        // Exponential backoff
        await this.sleep(Math.pow(2, attempt) * 1000)
      }
    }
    
    throw new Error(`Failed after 3 attempts: ${lastError.message}`)
  }
  
  executeOnce(data) {
    return new Promise((resolve, reject) => {
      const worker = this.getWorker()
      
      // Timeout
      const timeout = setTimeout(() => {
        reject(new Error('Worker timeout'))
        this.recreateWorker(worker)
      }, 30000)
      
      worker.worker.onmessage = (e) => {
        clearTimeout(timeout)
        
        if (e.data.error) {
          reject(new Error(e.data.error))
        } else {
          resolve(e.data)
        }
      }
      
      worker.worker.onerror = (error) => {
        clearTimeout(timeout)
        reject(error)
        this.recreateWorker(worker)
      }
      
      worker.worker.postMessage(data)
    })
  }
  
  recreateWorker(workerInfo) {
    workerInfo.worker.terminate()
    workerInfo.worker = new Worker(this.script)
    workerInfo.busy = false
  }
  
  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms))
  }
}
```

### Worker Error Handling:

```javascript
// worker.js
self.addEventListener('error', (event) => {
  console.error('Worker error:', event.error)
  self.postMessage({ error: event.error.message })
})

self.addEventListener('unhandledrejection', (event) => {
  console.error('Unhandled rejection:', event.reason)
  self.postMessage({ error: event.reason })
})

self.onmessage = async (e) => {
  try {
    const result = await processData(e.data)
    self.postMessage({ result })
  } catch (error) {
    self.postMessage({ error: error.message })
  }
}
```

---

## Testing Concurrent Code

### Unit Testing:

```javascript
// Test worker pool
describe('WorkerPool', () => {
  let pool
  
  beforeEach(() => {
    pool = new WorkerPool('test-worker.js', 2)
  })
  
  afterEach(() => {
    pool.terminate()
  })
  
  test('executes tasks concurrently', async () => {
    const start = Date.now()
    
    await Promise.all([
      pool.execute({ delay: 100 }),
      pool.execute({ delay: 100 })
    ])
    
    const duration = Date.now() - start
    
    // Should take ~100ms (parallel), not 200ms (sequential)
    expect(duration).toBeLessThan(150)
  })
  
  test('handles errors', async () => {
    await expect(
      pool.execute({ shouldFail: true })
    ).rejects.toThrow()
  })
  
  test('respects concurrency limit', async () => {
    const tasks = Array(10).fill(null).map(() => 
      pool.execute({ delay: 100 })
    )
    
    // Monitor active workers
    expect(pool.activeCount).toBeLessThanOrEqual(2)
    
    await Promise.all(tasks)
  })
})
```

### Race Condition Testing:

```javascript
// Test for race conditions
test('no race condition in counter', async () => {
  const iterations = 1000
  const workerCount = 4
  
  const sharedBuffer = new SharedArrayBuffer(4)
  const counter = new Int32Array(sharedBuffer)
  
  const workers = Array.from({ length: workerCount }, () => 
    new Worker('counter-worker.js')
  )
  
  await Promise.all(workers.map(worker => 
    new Promise((resolve) => {
      worker.onmessage = () => resolve()
      worker.postMessage({ buffer: sharedBuffer, iterations })
    })
  ))
  
  // Should be exactly workerCount * iterations
  expect(counter[0]).toBe(workerCount * iterations)
  
  workers.forEach(w => w.terminate())
})
```

---

## Debugging Strategies

### Logging Helper:

```javascript
class ConcurrencyLogger {
  constructor(enabled = true) {
    this.enabled = enabled
    this.events = []
  }
  
  log(category, message, data = {}) {
    if (!this.enabled) return
    
    const event = {
      timestamp: Date.now(),
      category,
      message,
      data,
      thread: self.name || 'main'
    }
    
    this.events.push(event)
    console.log(`[${category}] ${message}`, data)
  }
  
  getTimeline() {
    return this.events.sort((a, b) => a.timestamp - b.timestamp)
  }
  
  visualize() {
    const timeline = this.getTimeline()
    const grouped = {}
    
    timeline.forEach(event => {
      if (!grouped[event.thread]) {
        grouped[event.thread] = []
      }
      grouped[event.thread].push(event)
    })
    
    console.table(grouped)
  }
}

// Usage
const logger = new ConcurrencyLogger()

logger.log('worker', 'Task started', { taskId: 1 })
logger.log('worker', 'Task completed', { taskId: 1, duration: 100 })

logger.visualize()
```

### Chrome DevTools:

```javascript
// Add meaningful names to workers
const worker = new Worker('process.js', { name: 'data-processor-1' })

// Use console.time for profiling
console.time('parallel-processing')
await processInParallel(data)
console.timeEnd('parallel-processing')

// Use performance marks
performance.mark('task-start')
await executeTask()
performance.mark('task-end')
performance.measure('task-duration', 'task-start', 'task-end')
```

---

## Security Considerations

### Content Security Policy:

```javascript
// ❌ Insecure: Dynamic code
const code = `self.onmessage = (e) => { ${userInput} }`
const blob = new Blob([code])
const worker = new Worker(URL.createObjectURL(blob))

// ✅ Secure: Static worker files
const worker = new Worker('/workers/process.js')

// ✅ CSP headers
// Content-Security-Policy: worker-src 'self'
```

### Input Validation:

```javascript
// worker.js
self.onmessage = (e) => {
  const { data } = e
  
  // ✅ Validate input
  if (!data || typeof data.value !== 'number') {
    self.postMessage({ error: 'Invalid input' })
    return
  }
  
  if (data.value < 0 || data.value > 1000000) {
    self.postMessage({ error: 'Value out of range' })
    return
  }
  
  const result = process(data.value)
  self.postMessage({ result })
}
```

### SharedArrayBuffer Security:

```javascript
// ✅ Required headers for SharedArrayBuffer
// Cross-Origin-Opener-Policy: same-origin
// Cross-Origin-Embedder-Policy: require-corp

// Check availability
if (typeof SharedArrayBuffer === 'undefined') {
  console.warn('SharedArrayBuffer not available')
  // Fallback to message passing
}
```

---

## Design Patterns

### 1. Pipeline Pattern:

```javascript
class Pipeline {
  constructor() {
    this.stages = []
  }
  
  addStage(stage) {
    this.stages.push(stage)
    return this
  }
  
  async execute(input) {
    let result = input
    
    for (const stage of this.stages) {
      result = await stage(result)
    }
    
    return result
  }
}

// Usage
const pipeline = new Pipeline()
  .addStage(data => fetchData(data))
  .addStage(data => processInWorker(data))
  .addStage(data => saveToDatabase(data))

await pipeline.execute({ id: 123 })
```

### 2. Map-Reduce Pattern:

```javascript
async function mapReduce(data, mapFn, reduceFn, initialValue) {
  // Map phase (parallel)
  const mapped = await parallelMap(data, mapFn)
  
  // Reduce phase (sequential)
  return mapped.reduce(reduceFn, initialValue)
}

// Usage
const wordCount = await mapReduce(
  documents,
  doc => doc.split(' '),  // Map: split into words
  (counts, words) => {    // Reduce: count words
    words.forEach(word => {
      counts[word] = (counts[word] || 0) + 1
    })
    return counts
  },
  {}
)
```

---

## Common Anti-Patterns

### ❌ Anti-Pattern 1: Creating Too Many Workers

```javascript
// ❌ Bad
data.forEach(item => {
  const worker = new Worker('process.js')
  worker.postMessage(item)
})

// ✅ Good
const pool = new WorkerPool('process.js', 4)
await Promise.all(data.map(item => pool.execute(item)))
```

### ❌ Anti-Pattern 2: Blocking Main Thread

```javascript
// ❌ Bad
worker.onmessage = (e) => {
  for (let i = 0; i < 1000000000; i++) {} // Blocks!
  updateUI(e.data)
}

// ✅ Good
worker.onmessage = (e) => {
  requestAnimationFrame(() => {
    updateUI(e.data)
  })
}
```

### ❌ Anti-Pattern 3: Ignoring Errors

```javascript
// ❌ Bad
worker.postMessage(data)

// ✅ Good
worker.onerror = (error) => {
  console.error('Worker error:', error)
  handleError(error)
}

worker.postMessage(data)
```

---

## Summary

### Key Principles:
1. Start simple, optimize when needed
2. Use worker pools
3. Handle errors comprehensively
4. Test concurrent code thoroughly
5. Profile before optimizing

### Checklist:
- ✅ Worker pools for reuse
- ✅ Error handling and retries
- ✅ Cleanup on unmount
- ✅ Input validation
- ✅ Performance monitoring
- ✅ Security headers (SharedArrayBuffer)
- ✅ Unit tests for concurrency

### Resources:
- MDN Web Workers
- Chrome DevTools Performance
- Web.dev Concurrency Patterns
- JavaScript Concurrency Model

### Remember:
- Concurrency adds complexity
- Measure real performance gains
- Simpler is often better
- Test edge cases
- Monitor production performance
