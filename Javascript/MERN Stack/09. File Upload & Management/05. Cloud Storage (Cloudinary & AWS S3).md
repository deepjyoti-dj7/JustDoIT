# 05. Cloud Storage (Cloudinary & AWS S3)

## Introduction

Cloud storage services like **Cloudinary** and **AWS S3** provide scalable, reliable, and cost-effective solutions for storing and serving files. They offer CDN delivery, automatic optimization, and transformation capabilities.

---

## Why Cloud Storage?

### Benefits

1. **Scalability** - No server disk space limits
2. **CDN Delivery** - Fast global content delivery
3. **Automatic Optimization** - Image compression, format conversion
4. **Transformations** - Resize, crop, filter on-the-fly
5. **Reliability** - 99.9%+ uptime, automatic backups
6. **Cost-Effective** - Pay for what you use
7. **Security** - Built-in encryption, access control

### Local vs Cloud Storage

| Feature | Local Storage | Cloud Storage |
|---------|---------------|---------------|
| **Scalability** | Limited by disk | Unlimited |
| **Speed** | Fast locally | Fast globally (CDN) |
| **Cost** | Server costs | Usage-based |
| **Backup** | Manual | Automatic |
| **Transformations** | Manual processing | Automatic |
| **Maintenance** | High | Low |

---

## Cloudinary Integration

### Setup

```bash
npm install cloudinary multer-storage-cloudinary
```

### Configuration

```javascript
// config/cloudinary.js
const cloudinary = require('cloudinary').v2;
const { CloudinaryStorage } = require('multer-storage-cloudinary');
const multer = require('multer');

// Configure Cloudinary
cloudinary.config({
  cloud_name: process.env.CLOUDINARY_CLOUD_NAME,
  api_key: process.env.CLOUDINARY_API_KEY,
  api_secret: process.env.CLOUDINARY_API_SECRET
});

// Create storage engine
const storage = new CloudinaryStorage({
  cloudinary: cloudinary,
  params: {
    folder: 'uploads', // Folder in Cloudinary
    allowed_formats: ['jpg', 'jpeg', 'png', 'gif', 'webp'],
    transformation: [{ width: 1000, height: 1000, crop: 'limit' }]
  }
});

const upload = multer({ storage });

module.exports = { cloudinary, upload };
```

### Basic Upload

```javascript
// routes/upload.js
const express = require('express');
const { upload } = require('../config/cloudinary');

const router = express.Router();

router.post('/image', upload.single('image'), (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ message: 'No file uploaded' });
    }
    
    res.json({
      message: 'Image uploaded successfully',
      url: req.file.path,           // Cloudinary URL
      publicId: req.file.filename    // Cloudinary public_id
    });
  } catch (error) {
    res.status(500).json({ message: error.message });
  }
});

module.exports = router;
```

### Advanced Configuration

```javascript
// config/cloudinary.js
const storage = new CloudinaryStorage({
  cloudinary: cloudinary,
  params: async (req, file) => {
    // Dynamic configuration based on file type
    const folder = file.mimetype.startsWith('image/') ? 'images' : 'documents';
    
    return {
      folder: `uploads/${folder}`,
      allowed_formats: ['jpg', 'jpeg', 'png', 'gif', 'webp', 'pdf'],
      public_id: `${Date.now()}-${file.originalname.split('.')[0]}`,
      resource_type: 'auto', // auto, image, video, raw
      
      // Image transformations
      transformation: file.mimetype.startsWith('image/') 
        ? [
            { width: 1000, height: 1000, crop: 'limit' },
            { quality: 'auto' },
            { fetch_format: 'auto' }
          ]
        : undefined
    };
  }
});
```

### Multiple Files Upload

```javascript
router.post('/gallery', upload.array('photos', 10), async (req, res) => {
  try {
    if (!req.files || req.files.length === 0) {
      return res.status(400).json({ message: 'No files uploaded' });
    }
    
    const uploadedFiles = req.files.map(file => ({
      url: file.path,
      publicId: file.filename,
      format: file.format,
      size: file.size
    }));
    
    res.json({
      message: `${req.files.length} images uploaded`,
      files: uploadedFiles
    });
  } catch (error) {
    res.status(500).json({ message: error.message });
  }
});
```

### Delete Files

```javascript
const { cloudinary } = require('../config/cloudinary');

router.delete('/image/:publicId', async (req, res) => {
  try {
    const { publicId } = req.params;
    
    // Delete from Cloudinary
    const result = await cloudinary.uploader.destroy(publicId);
    
    if (result.result === 'ok') {
      res.json({ message: 'Image deleted successfully' });
    } else {
      res.status(404).json({ message: 'Image not found' });
    }
  } catch (error) {
    res.status(500).json({ message: error.message });
  }
});
```

### Image Transformations

```javascript
// Get transformed image URL
const getTransformedUrl = (publicId, transformations) => {
  return cloudinary.url(publicId, transformations);
};

// Examples
const thumbnail = getTransformedUrl('sample', {
  width: 200,
  height: 200,
  crop: 'fill',
  gravity: 'face'
});

const blurred = getTransformedUrl('sample', {
  effect: 'blur:300'
});

const watermarked = getTransformedUrl('sample', {
  overlay: 'watermark',
  gravity: 'south_east',
  x: 10,
  y: 10
});
```

---

## AWS S3 Integration

### Setup

```bash
npm install aws-sdk multer-s3
```

### Configuration

```javascript
// config/s3.js
const AWS = require('aws-sdk');
const multer = require('multer');
const multerS3 = require('multer-s3');
const path = require('path');

// Configure AWS
AWS.config.update({
  accessKeyId: process.env.AWS_ACCESS_KEY_ID,
  secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,
  region: process.env.AWS_REGION
});

const s3 = new AWS.S3();

// Create storage engine
const upload = multer({
  storage: multerS3({
    s3: s3,
    bucket: process.env.AWS_BUCKET_NAME,
    acl: 'public-read', // public-read, private, etc.
    metadata: (req, file, cb) => {
      cb(null, { fieldName: file.fieldname });
    },
    key: (req, file, cb) => {
      const uniqueSuffix = Date.now() + '-' + Math.round(Math.random() * 1E9);
      const filename = file.fieldname + '-' + uniqueSuffix + path.extname(file.originalname);
      cb(null, filename);
    }
  }),
  limits: { fileSize: 5 * 1024 * 1024 }, // 5MB
  fileFilter: (req, file, cb) => {
    const allowedTypes = /jpeg|jpg|png|gif/;
    const extname = allowedTypes.test(path.extname(file.originalname).toLowerCase());
    const mimetype = allowedTypes.test(file.mimetype);
    
    if (extname && mimetype) {
      cb(null, true);
    } else {
      cb(new Error('Only images are allowed'));
    }
  }
});

module.exports = { s3, upload };
```

### Basic Upload

```javascript
// routes/upload.js
const { upload } = require('../config/s3');

router.post('/s3/upload', upload.single('image'), (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ message: 'No file uploaded' });
    }
    
    res.json({
      message: 'File uploaded to S3',
      url: req.file.location,      // S3 URL
      key: req.file.key,            // S3 key
      bucket: req.file.bucket,      // Bucket name
      size: req.file.size
    });
  } catch (error) {
    res.status(500).json({ message: error.message });
  }
});
```

### Advanced S3 Configuration

```javascript
const upload = multer({
  storage: multerS3({
    s3: s3,
    bucket: process.env.AWS_BUCKET_NAME,
    acl: 'public-read',
    contentType: multerS3.AUTO_CONTENT_TYPE,
    
    // Organize files by date
    key: (req, file, cb) => {
      const date = new Date();
      const year = date.getFullYear();
      const month = String(date.getMonth() + 1).padStart(2, '0');
      const day = String(date.getDate()).padStart(2, '0');
      
      const folder = `uploads/${year}/${month}/${day}`;
      const uniqueSuffix = Date.now() + '-' + Math.round(Math.random() * 1E9);
      const filename = `${folder}/${uniqueSuffix}${path.extname(file.originalname)}`;
      
      cb(null, filename);
    },
    
    // Add metadata
    metadata: (req, file, cb) => {
      cb(null, {
        originalName: file.originalname,
        uploadedBy: req.user?.id || 'anonymous',
        uploadedAt: new Date().toISOString()
      });
    }
  })
});
```

### Delete Files from S3

```javascript
const { s3 } = require('../config/s3');

router.delete('/s3/delete/:key', async (req, res) => {
  try {
    const { key } = req.params;
    
    const params = {
      Bucket: process.env.AWS_BUCKET_NAME,
      Key: key
    };
    
    await s3.deleteObject(params).promise();
    
    res.json({ message: 'File deleted from S3' });
  } catch (error) {
    res.status(500).json({ message: error.message });
  }
});
```

### List Files from S3

```javascript
router.get('/s3/files', async (req, res) => {
  try {
    const params = {
      Bucket: process.env.AWS_BUCKET_NAME,
      Prefix: 'uploads/', // Filter by folder
      MaxKeys: 100
    };
    
    const data = await s3.listObjectsV2(params).promise();
    
    const files = data.Contents.map(file => ({
      key: file.Key,
      size: file.Size,
      lastModified: file.LastModified,
      url: `https://${process.env.AWS_BUCKET_NAME}.s3.${process.env.AWS_REGION}.amazonaws.com/${file.Key}`
    }));
    
    res.json({ files });
  } catch (error) {
    res.status(500).json({ message: error.message });
  }
});
```

### Generate Signed URLs (Private Files)

```javascript
router.get('/s3/signed-url/:key', async (req, res) => {
  try {
    const { key } = req.params;
    
    const params = {
      Bucket: process.env.AWS_BUCKET_NAME,
      Key: key,
      Expires: 60 * 60 // URL expires in 1 hour
    };
    
    const url = await s3.getSignedUrlPromise('getObject', params);
    
    res.json({ url });
  } catch (error) {
    res.status(500).json({ message: error.message });
  }
});
```

---

## Using Memory Storage for Cloud Upload

Instead of saving to disk first, upload directly to cloud.

```javascript
const multer = require('multer');
const { cloudinary } = require('./config/cloudinary');
const streamifier = require('streamifier');

const upload = multer({ storage: multer.memoryStorage() });

router.post('/direct-upload', upload.single('image'), (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ message: 'No file uploaded' });
    }
    
    // Upload buffer to Cloudinary
    const uploadStream = cloudinary.uploader.upload_stream(
      {
        folder: 'uploads',
        resource_type: 'auto'
      },
      (error, result) => {
        if (error) {
          return res.status(500).json({ message: error.message });
        }
        
        res.json({
          message: 'File uploaded to Cloudinary',
          url: result.secure_url,
          publicId: result.public_id
        });
      }
    );
    
    streamifier.createReadStream(req.file.buffer).pipe(uploadStream);
  } catch (error) {
    res.status(500).json({ message: error.message });
  }
});
```

---

## Environment Variables

```bash
# .env

# Cloudinary
CLOUDINARY_CLOUD_NAME=your_cloud_name
CLOUDINARY_API_KEY=your_api_key
CLOUDINARY_API_SECRET=your_api_secret

# AWS S3
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
AWS_REGION=us-east-1
AWS_BUCKET_NAME=your-bucket-name
```

---

## Interview Questions

**Q1: What are the benefits of cloud storage over local storage?**
- Scalability (unlimited storage)
- Global CDN delivery
- Automatic backups and redundancy
- Built-in transformations
- No server maintenance

**Q2: How do you upload files to Cloudinary with Multer?**
```javascript
const { CloudinaryStorage } = require('multer-storage-cloudinary');
const storage = new CloudinaryStorage({
  cloudinary: cloudinary,
  params: { folder: 'uploads' }
});
const upload = multer({ storage });
```

**Q3: How do you delete files from Cloudinary?**
```javascript
await cloudinary.uploader.destroy(publicId);
```

**Q4: What's the difference between ACL options in S3?**
- `public-read`: Anyone can read, only owner can write
- `private`: Only owner can read/write
- `public-read-write`: Anyone can read/write (not recommended)

**Q5: How do you generate signed URLs for private S3 files?**
```javascript
const url = await s3.getSignedUrlPromise('getObject', {
  Bucket: bucketName,
  Key: key,
  Expires: 3600 // 1 hour
});
```

---

## Best Practices

1. **Use environment variables** for credentials
2. **Never commit API keys** to version control
3. **Set appropriate ACL** (public-read for public files, private for sensitive)
4. **Organize files in folders** (by date, user, category)
5. **Use signed URLs** for private content
6. **Implement rate limiting** to prevent abuse
7. **Delete unused files** to reduce costs
8. **Use CDN** for fast global delivery
9. **Enable automatic backups** and versioning
10. **Monitor usage and costs** regularly

---

## Summary

- **Cloudinary**: Easy setup, built-in transformations, CDN delivery
- **AWS S3**: More control, cheaper at scale, requires more setup
- **multer-storage-cloudinary**: Direct upload to Cloudinary
- **multer-s3**: Direct upload to S3
- **Memory storage**: Upload buffers directly without saving to disk
- **Transformations**: Resize, crop, optimize on-the-fly
- **Signed URLs**: Secure access to private files
- **Delete files**: `cloudinary.uploader.destroy()` or `s3.deleteObject()`
