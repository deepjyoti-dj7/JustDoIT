# 20. Performance Optimization

## Why Performance Matters?

- Faster response times
- Handle more users
- Lower server costs
- Better user experience

---

## Measuring Performance

### console.time()

```javascript
console.time('operation');

// Your code here
for (let i = 0; i < 1000000; i++) {
  // ...
}

console.timeEnd('operation');
// Output: operation: 123.456ms
```

### performance API

```javascript
const { performance } = require('perf_hooks');

const start = performance.now();

// Your code
doSomething();

const end = performance.now();
console.log(`Execution time: ${end - start}ms`);
```

### Benchmarking

```bash
npm install benchmark
```

```javascript
const Benchmark = require('benchmark');
const suite = new Benchmark.Suite;

suite
  .add('Array#forEach', function() {
    [1, 2, 3].forEach(x => x * 2);
  })
  .add('For loop', function() {
    const arr = [1, 2, 3];
    for (let i = 0; i < arr.length; i++) {
      arr[i] * 2;
    }
  })
  .on('cycle', function(event) {
    console.log(String(event.target));
  })
  .on('complete', function() {
    console.log('Fastest is ' + this.filter('fastest').map('name'));
  })
  .run();
```

---

## Use Async Operations

```javascript
// ❌ Blocking (slow)
const fs = require('fs');
const data = fs.readFileSync('large-file.txt');
console.log(data);

// ✅ Non-blocking (fast)
fs.readFile('large-file.txt', (err, data) => {
  if (err) throw err;
  console.log(data);
});

// ✅ Promises (best)
const fs = require('fs').promises;
const data = await fs.readFile('large-file.txt');
```

---

## Use Streams

```javascript
// ❌ Load entire file (memory intensive)
const data = await fs.readFile('huge-file.txt');
res.send(data);

// ✅ Stream (memory efficient)
const stream = fs.createReadStream('huge-file.txt');
stream.pipe(res);
```

---

## Caching

### In-Memory Caching

```javascript
const cache = {};

app.get('/api/users/:id', async (req, res) => {
  const { id } = req.params;
  
  // Check cache
  if (cache[id]) {
    console.log('From cache');
    return res.json(cache[id]);
  }
  
  // Fetch from database
  const user = await db.users.findById(id);
  
  // Store in cache
  cache[id] = user;
  
  res.json(user);
});
```

### Redis Caching

```javascript
const redis = require('redis');
const client = redis.createClient();

app.get('/api/users/:id', async (req, res) => {
  const { id } = req.params;
  
  // Check Redis
  const cached = await client.get(`user:${id}`);
  if (cached) {
    return res.json(JSON.parse(cached));
  }
  
  // Fetch from database
  const user = await db.users.findById(id);
  
  // Cache for 1 hour
  await client.setEx(`user:${id}`, 3600, JSON.stringify(user));
  
  res.json(user);
});
```

---

## Connection Pooling

### Database Connection Pool

```javascript
const { Pool } = require('pg');

// ✅ Use connection pool
const pool = new Pool({
  host: 'localhost',
  user: 'admin',
  database: 'mydb',
  max: 20,  // Max connections
  idleTimeoutMillis: 30000
});

// Reuse connections
app.get('/users', async (req, res) => {
  const result = await pool.query('SELECT * FROM users');
  res.json(result.rows);
});
```

### HTTP Keep-Alive

```javascript
const http = require('http');

const agent = new http.Agent({
  keepAlive: true,
  maxSockets: 50
});

http.get('http://api.example.com', { agent }, (res) => {
  // Connection reused
});
```

---

## Compression

```javascript
const express = require('express');
const compression = require('compression');

const app = express();

// Enable gzip compression
app.use(compression());

app.get('/data', (req, res) => {
  res.json({ /* large data */ });
});
```

---

## Optimize Database Queries

### Use Indexes

```javascript
// Create index
db.users.createIndex({ email: 1 });

// Query uses index (fast)
db.users.find({ email: 'john@example.com' });
```

### Select Only Needed Fields

```javascript
// ❌ Get all fields
const users = await User.find();

// ✅ Get only needed fields
const users = await User.find().select('name email');
```

### Pagination

```javascript
// ❌ Load all users
app.get('/users', async (req, res) => {
  const users = await User.find();  // Could be millions!
  res.json(users);
});

// ✅ Paginate
app.get('/users', async (req, res) => {
  const page = parseInt(req.query.page) || 1;
  const limit = 20;
  const skip = (page - 1) * limit;
  
  const users = await User.find()
    .limit(limit)
    .skip(skip);
  
  res.json(users);
});
```

---

## Optimize Loops

```javascript
// ❌ Slow (recalculates length each iteration)
for (let i = 0; i < array.length; i++) {
  // ...
}

// ✅ Faster (cache length)
const len = array.length;
for (let i = 0; i < len; i++) {
  // ...
}

// ✅ Best (modern)
for (const item of array) {
  // ...
}
```

---

## Avoid Blocking the Event Loop

```javascript
// ❌ Blocks event loop
app.get('/compute', (req, res) => {
  let result = 0;
  for (let i = 0; i < 10000000000; i++) {
    result += i;
  }
  res.json({ result });
});

// ✅ Use worker thread
const { Worker } = require('worker_threads');

app.get('/compute', (req, res) => {
  const worker = new Worker('./compute-worker.js');
  
  worker.on('message', (result) => {
    res.json({ result });
  });
  
  worker.postMessage({ count: 10000000000 });
});
```

---

## Use Clustering

```javascript
const cluster = require('cluster');
const os = require('os');

if (cluster.isMaster) {
  // Fork workers (one per CPU core)
  for (let i = 0; i < os.cpus().length; i++) {
    cluster.fork();
  }
} else {
  // Worker process
  const app = require('./app');
  app.listen(3000);
}
```

---

## Optimize JSON Operations

```javascript
// ❌ Slow for large objects
const json = JSON.stringify(largeObject);

// ✅ Faster (streaming)
const JSONStream = require('JSONStream');

const stream = JSONStream.stringify();
stream.pipe(res);

data.forEach(item => stream.write(item));
stream.end();
```

---

## Use Native Methods

```javascript
// ❌ Slower
const doubled = [];
for (let i = 0; i < arr.length; i++) {
  doubled.push(arr[i] * 2);
}

// ✅ Faster (native)
const doubled = arr.map(x => x * 2);
```

---

## Lazy Loading

```javascript
// ❌ Load everything upfront
const express = require('express');
const mongoose = require('mongoose');
const jwt = require('jsonwebtoken');
const bcrypt = require('bcrypt');
// ... many more

// ✅ Load when needed
app.get('/auth/login', (req, res) => {
  const jwt = require('jsonwebtoken');  // Loaded only for auth routes
  // ...
});
```

---

## Memoization

Cache function results:

```javascript
function memoize(fn) {
  const cache = {};
  
  return function(...args) {
    const key = JSON.stringify(args);
    
    if (cache[key]) {
      console.log('From cache');
      return cache[key];
    }
    
    const result = fn(...args);
    cache[key] = result;
    return result;
  };
}

// Usage
function expensiveCalculation(n) {
  console.log('Computing...');
  let result = 0;
  for (let i = 0; i < n; i++) {
    result += i;
  }
  return result;
}

const memoized = memoize(expensiveCalculation);

console.log(memoized(1000000));  // Computing... then result
console.log(memoized(1000000));  // From cache (instant)
```

---

## Debouncing & Throttling

### Debounce (Wait for pause)

```javascript
function debounce(fn, delay) {
  let timeout;
  return function(...args) {
    clearTimeout(timeout);
    timeout = setTimeout(() => fn(...args), delay);
  };
}

// Usage: Search input
const search = debounce((query) => {
  console.log('Searching:', query);
}, 500);

// User types: a, ab, abc
// Only searches once user stops typing for 500ms
```

### Throttle (Limit frequency)

```javascript
function throttle(fn, limit) {
  let inThrottle;
  return function(...args) {
    if (!inThrottle) {
      fn(...args);
      inThrottle = true;
      setTimeout(() => inThrottle = false, limit);
    }
  };
}

// Usage: Scroll events
const onScroll = throttle(() => {
  console.log('Scrolling');
}, 1000);

// Runs max once per second
```

---

## Optimize Regular Expressions

```javascript
// ❌ Slow (creates new regex each time)
function validate(str) {
  return /^[a-zA-Z0-9]+$/.test(str);
}

// ✅ Fast (reuse regex)
const regex = /^[a-zA-Z0-9]+$/;
function validate(str) {
  return regex.test(str);
}
```

---

## Use CDN for Static Files

```javascript
// ❌ Serve from your server
app.use(express.static('public'));

// ✅ Use CDN
// Upload static files to CDN (Cloudflare, AWS CloudFront)
// Reference in HTML: <script src="https://cdn.example.com/app.js"></script>
```

---

## Enable HTTP/2

```javascript
const http2 = require('http2');
const fs = require('fs');

const server = http2.createSecureServer({
  key: fs.readFileSync('private-key.pem'),
  cert: fs.readFileSync('certificate.pem')
});

server.on('stream', (stream, headers) => {
  stream.respond({ ':status': 200 });
  stream.end('<h1>Hello HTTP/2</h1>');
});

server.listen(3000);
```

---

## Monitor Performance

### Using clinic.js

```bash
npm install -g clinic

# Detect performance issues
clinic doctor -- node app.js

# Flame graph
clinic flame -- node app.js

# Bubble graph
clinic bubbleprof -- node app.js
```

### Using autocannon (Load Testing)

```bash
npm install -g autocannon

# Test API performance
autocannon http://localhost:3000/api/users
```

---

## Performance Checklist

✅ **Use async operations**: Don't block event loop  
✅ **Enable caching**: Redis, in-memory  
✅ **Use compression**: gzip responses  
✅ **Optimize database**: Indexes, select fields, pagination  
✅ **Use connection pooling**: Reuse connections  
✅ **Use clustering**: Utilize all CPU cores  
✅ **Use streams**: For large files  
✅ **Lazy load modules**: Load when needed  
✅ **Monitor performance**: Use profiling tools  

---

## Quick Wins

| Optimization | Effort | Impact |
|--------------|--------|--------|
| Enable compression | Low | High |
| Add caching | Medium | High |
| Use clustering | Low | High |
| Database indexes | Low | High |
| Connection pooling | Low | Medium |
| Use streams | Medium | Medium |
| CDN for static files | Low | High |

---

## Summary

**Key Principles:**
- Avoid blocking the event loop
- Use async/await for I/O operations
- Cache frequently accessed data
- Use streaming for large data
- Optimize database queries
- Use clustering for multi-core CPUs
- Monitor and measure performance

**Tools:**
- **clinic.js** - Performance profiling
- **autocannon** - Load testing
- **Redis** - Caching
- **PM2** - Process management

**Remember:** Measure first, then optimize!

**Next:** Learn about testing in Node.js!
