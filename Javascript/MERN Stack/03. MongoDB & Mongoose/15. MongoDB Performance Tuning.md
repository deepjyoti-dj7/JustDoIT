# 15. MongoDB Performance Tuning

## Query Performance

### 1. Use Indexes

âœ… **Create indexes on frequently queried fields:**

```javascript
// Single field index
db.users.createIndex({ email: 1 });

// Compound index
db.orders.createIndex({ customerId: 1, createdAt: -1 });

// Mongoose
const schema = new mongoose.Schema({
  email: { type: String, index: true },
  status: { type: String, index: true }
});

schema.index({ city: 1, age: -1 });
```

### 2. Check Query Performance

```javascript
// Explain query
db.users.find({ email: 'john@example.com' }).explain('executionStats');

// Mongoose
const result = await User.find({ email: 'john@example.com' }).explain();
```

**Look for:**
- `IXSCAN` = Index scan âœ… (good)
- `COLLSCAN` = Collection scan âŒ (slow)

### 3. Use Projection

âœ… **Good:**
```javascript
// Only get needed fields
const users = await User.find().select('name email');
```

âŒ **Bad:**
```javascript
const users = await User.find();  // Gets all fields
```

### 4. Use lean()

âœ… **Good:**
```javascript
// Returns plain JS object (faster)
const users = await User.find().lean();
```

âŒ **Bad:**
```javascript
// Returns Mongoose document (slower)
const users = await User.find();
```

---

## Indexing Strategy

### 1. Index Design

**Equality â†’ Range â†’ Sort pattern:**

```javascript
// Query: { status: 'active', age: { $gt: 25 } } + sort by createdAt
db.users.createIndex({ status: 1, age: 1, createdAt: -1 });
```

### 2. Drop Unused Indexes

```javascript
// Check index usage
db.users.aggregate([{ $indexStats: {} }]);

// Drop unused index
db.users.dropIndex('oldIndex_1');
```

### 3. Index Size

```javascript
// Check index size
db.users.stats();
```

---

## Connection Pooling

### Configure Pool Size

```javascript
mongoose.connect(process.env.MONGO_URI, {
  maxPoolSize: 10,  // Max connections
  minPoolSize: 2,   // Min connections
  serverSelectionTimeoutMS: 5000,
  socketTimeoutMS: 45000
});
```

---

## Pagination

### Limit Results

âœ… **Good:**
```javascript
const page = 1;
const limit = 10;

const users = await User
  .find()
  .skip((page - 1) * limit)
  .limit(limit)
  .lean();

const total = await User.countDocuments();

res.json({
  users,
  page,
  totalPages: Math.ceil(total / limit)
});
```

### Cursor-Based Pagination (Better)

```javascript
// First page
const users = await User
  .find()
  .sort({ _id: -1 })
  .limit(10)
  .lean();

const lastId = users[users.length - 1]._id;

// Next page
const nextUsers = await User
  .find({ _id: { $lt: lastId } })
  .sort({ _id: -1 })
  .limit(10)
  .lean();
```

---

## Aggregation Performance

### 1. $match Early

âœ… **Good:**
```javascript
db.orders.aggregate([
  { $match: { status: 'completed' } },  // Filter first
  { $group: { _id: '$customerId', total: { $sum: '$amount' } } },
  { $sort: { total: -1 } }
]);
```

âŒ **Bad:**
```javascript
db.orders.aggregate([
  { $group: { _id: '$customerId', total: { $sum: '$amount' } } },
  { $match: { status: 'completed' } }  // âŒ Filter after grouping
]);
```

### 2. Use Indexes in $match

```javascript
// Create index
db.orders.createIndex({ status: 1, createdAt: -1 });

// Use in aggregation
db.orders.aggregate([
  { $match: { status: 'completed', createdAt: { $gte: startDate } } },
  // ...
]);
```

---

## Schema Design

### 1. Embedding vs Referencing

**Embedding (faster reads):**

âœ… **Use when:**
- Data is small
- One-to-few relationship
- Data doesn't change often

```javascript
const userSchema = new mongoose.Schema({
  name: String,
  address: {
    street: String,
    city: String,
    zipCode: String
  }
});
```

**Referencing (better for large data):**

âœ… **Use when:**
- Data is large
- Many-to-many relationship
- Data changes frequently

```javascript
const postSchema = new mongoose.Schema({
  title: String,
  author: { type: ObjectId, ref: 'User' }
});
```

### 2. Avoid Large Arrays

âŒ **Bad:**
```javascript
const userSchema = new mongoose.Schema({
  name: String,
  posts: [{ type: ObjectId, ref: 'Post' }]  // âŒ Can grow unbounded
});
```

âœ… **Good:**
```javascript
// Store reference on Post side
const postSchema = new mongoose.Schema({
  title: String,
  author: { type: ObjectId, ref: 'User' }
});
```

---

## Batch Operations

### Use insertMany

âœ… **Good:**
```javascript
const users = [
  { name: 'Alice', email: 'alice@example.com' },
  { name: 'Bob', email: 'bob@example.com' }
];

await User.insertMany(users);
```

âŒ **Bad:**
```javascript
for (const user of users) {
  await User.create(user);  // âŒ Slow
}
```

### Use bulkWrite

```javascript
await User.bulkWrite([
  { insertOne: { document: { name: 'Alice' } } },
  { updateOne: { filter: { _id: id }, update: { $set: { age: 30 } } } },
  { deleteOne: { filter: { email: 'old@example.com' } } }
]);
```

---

## Monitoring

### 1. Enable Profiling

```javascript
// Enable profiling for slow queries (>100ms)
db.setProfilingLevel(1, { slowms: 100 });

// View slow queries
db.system.profile.find().limit(10).sort({ ts: -1 });
```

### 2. Monitor Current Operations

```javascript
db.currentOp();
```

### 3. Database Stats

```javascript
db.stats();
db.users.stats();
```

---

## Caching

### Use Redis for Frequently Accessed Data

```javascript
const redis = require('redis');
const client = redis.createClient();

const getUser = async (userId) => {
  // Check cache
  const cached = await client.get(`user:${userId}`);
  if (cached) {
    return JSON.parse(cached);
  }
  
  // Fetch from DB
  const user = await User.findById(userId).lean();
  
  // Store in cache (1 hour)
  await client.setEx(`user:${userId}`, 3600, JSON.stringify(user));
  
  return user;
};
```

---

## Memory Management

### 1. Use Streams for Large Data

```javascript
const cursor = User.find().cursor();

cursor.on('data', (user) => {
  console.log(user);
});

cursor.on('end', () => {
  console.log('Done');
});
```

### 2. Close Connections

```javascript
process.on('SIGINT', async () => {
  await mongoose.connection.close();
  process.exit(0);
});
```

---

## Best Practices Summary

**Indexes:**
- âœ… Index frequently queried fields
- âœ… Use compound indexes for multi-field queries
- âœ… Drop unused indexes

**Queries:**
- âœ… Use projection (select only needed fields)
- âœ… Use lean() for read-only data
- âœ… Use pagination
- âœ… Use explain() to check performance

**Schema:**
- âœ… Embed for small, related data
- âœ… Reference for large or frequently changing data
- âœ… Avoid unbounded arrays

**Operations:**
- âœ… Use insertMany/bulkWrite for batch operations
- âœ… Use $match early in aggregations
- âœ… Use connection pooling

**Monitoring:**
- âœ… Enable profiling for slow queries
- âœ… Monitor current operations
- âœ… Check database stats

**Caching:**
- âœ… Use Redis for frequently accessed data
- âœ… Cache query results

---

## Performance Checklist

- [ ] Indexes on frequently queried fields
- [ ] Compound indexes for multi-field queries
- [ ] Use explain() to verify index usage
- [ ] Use projection to limit fields
- [ ] Use lean() for read-only queries
- [ ] Implement pagination
- [ ] Use $match early in aggregations
- [ ] Batch operations with insertMany
- [ ] Avoid unbounded arrays
- [ ] Enable query profiling
- [ ] Use connection pooling
- [ ] Cache frequently accessed data
- [ ] Close connections properly

---

## Summary

**Key Points:**
1. **Index everything you query**
2. **Use lean() for read-only data**
3. **Select only needed fields**
4. **Paginate large datasets**
5. **$match early in aggregations**
6. **Batch operations**
7. **Monitor slow queries**
8. **Cache frequently accessed data**

**Quick Wins:**
```javascript
// Add index
schema.index({ email: 1 });

// Use lean
const users = await User.find().lean();

// Select fields
const users = await User.find().select('name email');

// Paginate
const users = await User.find().limit(10).skip(10);
```

**MongoDB & Mongoose Section Complete! ðŸŽ‰**
