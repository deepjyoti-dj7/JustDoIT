# 01. Cache-Aside, Read-Through & Write-Through

## Caching Patterns Overview

Caching patterns define how applications interact with cache and database.

**Key Questions:**
1. When to populate cache?
2. When to update cache?
3. Who manages cache (app or cache layer)?
4. How to handle cache misses?

---

## Cache-Aside (Lazy Loading)

**Most popular pattern** - Application manages cache explicitly.

### How It Works

```
┌──────────────┐
│ Application  │
└──────┬───────┘
       │
       │ 1. Check cache
       ▼
┌──────────────┐
│    Cache     │
│   (Redis)    │
└──────────────┘
       │
       │ 2. Cache miss?
       │ 3. Query DB
       ▼
┌──────────────┐
│   Database   │
└──────────────┘
       │
       │ 4. Store in cache
       └─────────────────► Cache
```

### Implementation

#### Python

```python
import redis
import json

redis_client = redis.Redis(host='localhost', port=6379)

def get_user(user_id):
    cache_key = f"user:{user_id}"
    
    # 1. Try cache first
    cached = redis_client.get(cache_key)
    if cached:
        print("Cache hit")
        return json.loads(cached)
    
    # 2. Cache miss - query database
    print("Cache miss")
    user = db.query(f"SELECT * FROM users WHERE id={user_id}")
    
    # 3. Store in cache with TTL
    redis_client.setex(
        cache_key,
        3600,  # 1 hour TTL
        json.dumps(user)
    )
    
    return user

def update_user(user_id, data):
    # 1. Update database
    db.update(f"UPDATE users SET ... WHERE id={user_id}")
    
    # 2. Invalidate cache
    redis_client.delete(f"user:{user_id}")
    # Or update cache:
    # redis_client.setex(f"user:{user_id}", 3600, json.dumps(data))
```

#### Node.js

```javascript
const redis = require('ioredis');
const client = new redis();

async function getUser(userId) {
  const cacheKey = `user:${userId}`;
  
  // 1. Try cache
  let cached = await client.get(cacheKey);
  if (cached) {
    console.log('Cache hit');
    return JSON.parse(cached);
  }
  
  // 2. Cache miss - query DB
  console.log('Cache miss');
  const user = await db.query(`SELECT * FROM users WHERE id=${userId}`);
  
  // 3. Store in cache
  await client.setex(cacheKey, 3600, JSON.stringify(user));
  
  return user;
}

async function updateUser(userId, data) {
  // 1. Update DB
  await db.update(`UPDATE users SET ... WHERE id=${userId}`);
  
  // 2. Invalidate cache
  await client.del(`user:${userId}`);
}
```

#### Java (Spring Boot)

```java
@Service
public class UserService {
    @Autowired
    private RedisTemplate<String, String> redisTemplate;
    
    @Autowired
    private UserRepository userRepository;
    
    public User getUser(Long userId) {
        String cacheKey = "user:" + userId;
        
        // 1. Try cache
        String cached = redisTemplate.opsForValue().get(cacheKey);
        if (cached != null) {
            return objectMapper.readValue(cached, User.class);
        }
        
        // 2. Cache miss - query DB
        User user = userRepository.findById(userId).orElse(null);
        
        // 3. Store in cache
        redisTemplate.opsForValue().set(
            cacheKey,
            objectMapper.writeValueAsString(user),
            1, TimeUnit.HOURS
        );
        
        return user;
    }
    
    public void updateUser(Long userId, User user) {
        // 1. Update DB
        userRepository.save(user);
        
        // 2. Invalidate cache
        redisTemplate.delete("user:" + userId);
    }
}
```

### Advantages

✅ **Simple to implement**
✅ **Cache only requested data** (efficient memory usage)
✅ **Resilient** - Cache failure doesn't break app
✅ **Works with existing code** (easy to add)

### Disadvantages

❌ **Cache miss penalty** - First request slow
❌ **Stale data** - Cache might be outdated
❌ **Application manages cache** - More code

### When to Use

- Read-heavy workloads
- Data changes infrequently
- Cache failures acceptable
- Simple caching needs

---

## Read-Through Cache

Cache layer automatically loads data from database on miss.

### How It Works

```
┌──────────────┐
│ Application  │
└──────┬───────┘
       │
       │ 1. Request data
       ▼
┌──────────────┐
│ Cache Layer  │◄─── Automatically queries DB on miss
│   (Redis)    │
└──────┬───────┘
       │
       │ 2. Cache miss? Auto-load from DB
       ▼
┌──────────────┐
│   Database   │
└──────────────┘
```

### Implementation

**Note:** Requires cache library/middleware that supports read-through.

#### Spring Boot (@Cacheable)

```java
@Service
public class UserService {
    
    @Cacheable(value = "users", key = "#userId")
    public User getUser(Long userId) {
        // This method is called only on cache miss
        // Spring automatically caches the result
        return userRepository.findById(userId).orElse(null);
    }
    
    @CacheEvict(value = "users", key = "#userId")
    public void updateUser(Long userId, User user) {
        userRepository.save(user);
        // Cache automatically invalidated
    }
}
```

**Configuration:**

```java
@Configuration
@EnableCaching
public class CacheConfig {
    
    @Bean
    public RedisCacheManager cacheManager(RedisConnectionFactory connectionFactory) {
        RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig()
            .entryTtl(Duration.ofHours(1))
            .serializeValuesWith(
                RedisSerializationContext.SerializationPair
                    .fromSerializer(new GenericJackson2JsonRedisSerializer())
            );
        
        return RedisCacheManager.builder(connectionFactory)
            .cacheDefaults(config)
            .build();
    }
}
```

### Advantages

✅ **Transparent caching** - App doesn't manage cache
✅ **Cleaner code** - No cache logic in business code
✅ **Consistent pattern** - Same behavior across app

### Disadvantages

❌ **Less control** - Cache behavior abstracted
❌ **Framework dependency** - Requires specific library
❌ **Still has cache miss penalty**

### When to Use

- Using framework with caching support (Spring, etc.)
- Want cleaner separation of concerns
- Prefer declarative approach

---

## Write-Through Cache

Data written to cache and database simultaneously.

### How It Works

```
┌──────────────┐
│ Application  │
└──────┬───────┘
       │
       │ 1. Write data
       ▼
┌──────────────┐
│ Cache Layer  │─────► 2. Write to DB
│   (Redis)    │       (Synchronous)
└──────────────┘
       │
       └──────────────► Cache always in sync
```

### Implementation

#### Python

```python
def update_user(user_id, data):
    cache_key = f"user:{user_id}"
    
    # 1. Update database (primary write)
    db.update(f"UPDATE users SET ... WHERE id={user_id}")
    
    # 2. Update cache immediately
    redis_client.setex(
        cache_key,
        3600,
        json.dumps(data)
    )
    # Cache always reflects latest data
```

#### Node.js

```javascript
async function updateUser(userId, data) {
  const cacheKey = `user:${userId}`;
  
  // 1. Update database
  await db.update(`UPDATE users SET ... WHERE id=${userId}`);
  
  // 2. Update cache immediately
  await client.setex(cacheKey, 3600, JSON.stringify(data));
}

async function createUser(data) {
  // 1. Insert into DB
  const user = await db.insert('INSERT INTO users ...');
  
  // 2. Write to cache
  await client.setex(
    `user:${user.id}`,
    3600,
    JSON.stringify(user)
  );
  
  return user;
}
```

#### Java (Spring Boot)

```java
@Service
public class UserService {
    
    @CachePut(value = "users", key = "#user.id")
    public User updateUser(User user) {
        // 1. Update DB
        User updated = userRepository.save(user);
        
        // 2. @CachePut updates cache automatically
        return updated;
    }
    
    @CachePut(value = "users", key = "#result.id")
    public User createUser(User user) {
        // 1. Insert into DB
        User created = userRepository.save(user);
        
        // 2. @CachePut adds to cache
        return created;
    }
}
```

### Advantages

✅ **Always consistent** - Cache always up-to-date
✅ **No stale data**
✅ **Fast reads** - Data already in cache

### Disadvantages

❌ **Write penalty** - Every write goes to cache + DB
❌ **Cache pollution** - Caches data that might not be read
❌ **Complexity** - Need to handle both write failures

### When to Use

- Consistency critical
- Read-heavy with occasional writes
- Can tolerate write latency

---

## Comparison

| Pattern | Cache Population | Cache Update | Consistency | Complexity |
|---------|-----------------|--------------|-------------|------------|
| **Cache-Aside** | On read (miss) | Manual invalidation | Eventual | Low |
| **Read-Through** | On read (miss) | Manual invalidation | Eventual | Medium |
| **Write-Through** | On write | Automatic | Strong | Medium |

---

## Combining Patterns

### Read-Through + Write-Through

```java
@Service
public class UserService {
    
    // Read-Through: Auto-load on cache miss
    @Cacheable(value = "users", key = "#userId")
    public User getUser(Long userId) {
        return userRepository.findById(userId).orElse(null);
    }
    
    // Write-Through: Update cache on write
    @CachePut(value = "users", key = "#user.id")
    public User updateUser(User user) {
        return userRepository.save(user);
    }
    
    // Evict on delete
    @CacheEvict(value = "users", key = "#userId")
    public void deleteUser(Long userId) {
        userRepository.deleteById(userId);
    }
}
```

---

## Best Practices

### 1. Always Set TTL

```python
# ❌ Bad: No TTL
redis_client.set(cache_key, data)

# ✅ Good: With TTL
redis_client.setex(cache_key, 3600, data)
```

### 2. Handle Cache Failures Gracefully

```python
def get_user(user_id):
    try:
        cached = redis_client.get(f"user:{user_id}")
        if cached:
            return json.loads(cached)
    except redis.RedisError:
        # Cache failure - continue to DB
        pass
    
    # Always return data from DB if cache fails
    return db.query(f"SELECT * FROM users WHERE id={user_id}")
```

### 3. Use Appropriate TTL

```python
# Hot data: Short TTL
redis_client.setex('trending:posts', 60, data)  # 1 minute

# Warm data: Medium TTL
redis_client.setex('user:profile', 3600, data)  # 1 hour

# Cold data: Long TTL
redis_client.setex('config:settings', 86400, data)  # 1 day
```

### 4. Monitor Cache Hit Rate

```python
def get_user_with_metrics(user_id):
    cached = redis_client.get(f"user:{user_id}")
    
    if cached:
        metrics.increment('cache.hit')
        return json.loads(cached)
    
    metrics.increment('cache.miss')
    user = db.query(f"SELECT * FROM users WHERE id={user_id}")
    redis_client.setex(f"user:{user_id}", 3600, json.dumps(user))
    return user
```

---

## Summary

**Cache-Aside (Lazy Loading):**
- App explicitly manages cache
- Load on cache miss
- Most popular pattern
- Use for: Read-heavy, simple caching

**Read-Through:**
- Cache layer auto-loads data
- Transparent to application
- Use for: Framework-based apps

**Write-Through:**
- Write to cache + DB simultaneously
- Always consistent
- Use for: Consistency-critical data

---

## Interview Questions & Answers

### Q1: What is Cache-Aside pattern?
**A:** Application explicitly manages cache:
1. Check cache for data
2. If miss, query database
3. Store result in cache
4. Return data

Most popular pattern. Simple to implement.

### Q2: What's the difference between Cache-Aside and Read-Through?
**A:**
- **Cache-Aside**: Application manages cache explicitly
- **Read-Through**: Cache layer auto-loads from DB on miss

```python
# Cache-Aside
if not redis.get(key):
    data = db.query()
    redis.set(key, data)

# Read-Through
@Cacheable  # Framework handles cache miss
def get_data():
    return db.query()
```

### Q3: What is Write-Through cache?
**A:** Data written to cache and database simultaneously:
```python
def update_user(user_id, data):
    db.update(...)        # Write to DB
    redis.set(key, data)  # Write to cache (same time)
```
Cache always consistent with DB.

### Q4: What are the disadvantages of Cache-Aside?
**A:**
1. **Cache miss penalty**: First request slow
2. **Stale data**: Cache might be outdated
3. **Manual management**: More code to maintain
4. **Eventual consistency**: Cache/DB might differ temporarily

### Q5: When should you use Write-Through cache?
**A:** When:
- Data consistency is critical
- Read-heavy workload with occasional writes
- Can tolerate write latency
- Want cache always up-to-date

**Don't use** for write-heavy workloads (too slow).

### Q6: How do you handle cache failures in Cache-Aside?
**A:** Graceful degradation:
```python
try:
    cached = redis.get(key)
    if cached:
        return cached
except RedisError:
    pass  # Continue to DB

return db.query()  # Always return data
```
Cache failure shouldn't break application.

### Q7: What's the cache miss penalty?
**A:** Time to:
1. Check cache (miss)
2. Query database
3. Store in cache
4. Return data

First request is slower. Subsequent requests are fast (cache hit).

### Q8: How do you invalidate cache in Cache-Aside?
**A:** Two approaches:

**1. Delete (lazy update):**
```python
db.update(...)
redis.delete(key)  # Next read will refresh
```

**2. Update (immediate):**
```python
db.update(...)
redis.set(key, new_data)  # Cache immediately updated
```

### Q9: What's the difference between @Cacheable and @CachePut?
**A:**
- **@Cacheable**: Load from cache, query DB only on miss (Read-Through)
- **@CachePut**: Always execute method, update cache with result (Write-Through)

```java
@Cacheable  // Skips method if cached
getUser() {...}

@CachePut   // Always executes, updates cache
updateUser() {...}
```

### Q10: Should you always set TTL on cached data?
**A:** **Yes!** Always set TTL to:
1. Prevent stale data
2. Free up memory
3. Handle cache/DB inconsistencies

```python
# ✅ Good
redis.setex(key, 3600, data)

# ❌ Bad (no TTL)
redis.set(key, data)
```

### Q11: What happens if cache write fails in Write-Through?
**A:** Database write succeeds but cache write fails → inconsistency!

Handle with:
```python
try:
    db.update(...)
    redis.set(key, data)
except RedisError:
    # Log error, cache will refresh on next read
    logger.error("Cache write failed")
```

### Q12: What's a good cache hit rate?
**A:** 
- **> 80%**: Good
- **> 90%**: Excellent
- **< 70%**: Investigate (wrong data cached, TTL too short, etc.)

### Q13: How do you implement Cache-Aside in Node.js?
**A:**
```javascript
async function getUser(userId) {
  const key = `user:${userId}`;
  
  // Try cache
  let cached = await redis.get(key);
  if (cached) return JSON.parse(cached);
  
  // Cache miss - query DB
  const user = await db.query(...);
  
  // Store in cache
  await redis.setex(key, 3600, JSON.stringify(user));
  
  return user;
}
```

### Q14: What's eventual consistency in caching?
**A:** Cache and database might temporarily have different data:

```python
# Time 0: Update DB
db.update(user, name="Jane")

# Time 1: Cache still has "John" (stale)
redis.get(key)  # "John"

# Time 2: Cache expires/invalidated
# Time 3: Cache refreshed with "Jane"
```

Eventually becomes consistent.

### Q15: Can you combine Read-Through and Write-Through?
**A:** Yes! Best of both:
```java
@Cacheable  // Read-Through
getUser() {...}

@CachePut   // Write-Through
updateUser() {...}

@CacheEvict
deleteUser() {...}
```
Reads and writes both cached automatically.

**Next:** Eviction Policies & Memory Management!