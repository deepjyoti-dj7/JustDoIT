# 01. Redis with Node.js (ioredis)

## Overview

This guide shows how to use Redis with Node.js using `ioredis` for production-ready features: robust connections, clustering, Sentinel, pipelines, Lua scripts, Streams, Pub/Sub, caching, rate limiting, and distributed locks.

---

## Setup

### Install

```bash
# Project init
mkdir -p node-redis && cd node-redis
npm init -y

# Install ioredis
npm install ioredis

# Optional utilities
npm install express morgan
```

### Connect

```javascript
const Redis = require('ioredis');

// Single instance
const redis = new Redis({
  host: process.env.REDIS_HOST || '127.0.0.1',
  port: Number(process.env.REDIS_PORT || 6379),
  password: process.env.REDIS_PASSWORD, // optional
  tls: process.env.REDIS_TLS ? {} : undefined // for managed Redis
});

redis.on('connect', () => console.log('Redis connected'));
redis.on('error', (err) => console.error('Redis error', err));
```

### Sentinel

```javascript
const sentinelRedis = new Redis({
  sentinels: [
    { host: '127.0.0.1', port: 26379 },
    { host: '127.0.0.1', port: 26380 }
  ],
  name: 'mymaster', // sentinel master name
  password: process.env.REDIS_PASSWORD
});
```

### Cluster

```javascript
const cluster = new Redis.Cluster([
  { host: '127.0.0.1', port: 7000 },
  { host: '127.0.0.1', port: 7001 },
  { host: '127.0.0.1', port: 7002 }
], {
  dnsLookup: (address, callback) => callback(null, address),
  scaleReads: 'slave', // read from replicas when safe
});
```

---

## Core Usage

### Strings

```javascript
await redis.set('user:1001:name', 'John', 'EX', 3600);
const name = await redis.get('user:1001:name');
```

### Hashes

```javascript
await redis.hset('user:1001', {
  name: 'John',
  email: 'john@example.com',
  age: 30
});
const user = await redis.hgetall('user:1001');
```

### Lists (Queues)

```javascript
await redis.lpush('queue:emails', JSON.stringify({ to: 'x@y.com' }));
const job = await redis.brpop('queue:emails', 5); // block up to 5s
```

### Sets

```javascript
await redis.sadd('tags:post:42', 'redis', 'nodejs');
const tags = await redis.smembers('tags:post:42');
```

### Sorted Sets (Leaderboards)

```javascript
await redis.zadd('leaderboard', 100, 'player:alice');
await redis.zincrby('leaderboard', 5, 'player:alice');
const top10 = await redis.zrevrange('leaderboard', 0, 9, 'WITHSCORES');
```

---

## Pipelines & Transactions

### Pipeline (batch, no atomicity)

```javascript
const pipeline = redis.pipeline();
pipeline.set('a', '1');
pipeline.incr('a');
const results = await pipeline.exec();
// [[null, 'OK'], [null, 2]]
```

### MULTI/EXEC (atomic)

```javascript
const tx = redis.multi();
tx.set('balance:alice', 100);
tx.decrby('balance:alice', 10);
const res = await tx.exec();
```

---

## Lua Scripting

```javascript
// Atomic rate limiter: allow N requests per window
const script = `
local key = KEYS[1]
local limit = tonumber(ARGV[1])
local window = tonumber(ARGV[2])
local current = redis.call('INCR', key)
if current == 1 then
  redis.call('EXPIRE', key, window)
end
return current <= limit
`

const allowed = await redis.eval(script, 1, 'rl:ip:1.2.3.4', 100, 60);
if (!allowed) throw new Error('Rate limit exceeded');
```

---

## Pub/Sub

```javascript
// Publisher
await redis.publish('events:user', JSON.stringify({ type: 'USER_CREATED', id: 1001 }));

// Subscriber
const sub = new Redis();
await sub.subscribe('events:user');
sub.on('message', (channel, message) => {
  const evt = JSON.parse(message);
  console.log('Event:', channel, evt);
});
```

---

## Streams (Consumer Groups)

```javascript
// Producer
await redis.xadd('stream:orders', '*', 'orderId', 'o-123', 'amount', '49.99');

// Setup group once
try {
  await redis.xgroup('CREATE', 'stream:orders', 'order-workers', '$', 'MKSTREAM');
} catch (e) {
  if (!String(e).includes('BUSYGROUP')) throw e;
}

// Consumer loop
async function consume(name) {
  while (true) {
    const resp = await redis.xreadgroup('GROUP', 'order-workers', name, 'COUNT', 10, 'BLOCK', 5000, 'STREAMS', 'stream:orders', '>' );
    if (!resp) continue;
    for (const [stream, messages] of resp) {
      for (const [id, fields] of messages) {
        try {
          // process fields
          await redis.xack('stream:orders', 'order-workers', id);
        } catch (err) {
          console.error('Processing failed, pending entry', id, err);
        }
      }
    }
  }
}
consume('worker-1');
```

---

## Caching Helpers

### Cache-Aside Wrapper

```javascript
async function cacheAside(key, ttlSeconds, loader) {
  const cached = await redis.get(key);
  if (cached) return JSON.parse(cached);
  const data = await loader();
  await redis.set(key, JSON.stringify(data), 'EX', ttlSeconds);
  return data;
}

// Usage: user profile
const profile = await cacheAside(`user:${userId}:profile`, 3600, () => db.getUser(userId));
```

### Express Middleware: Rate Limiting

```javascript
const rateLimiter = (keyPrefix = 'rl', limit = 100, window = 60) => async (req, res, next) => {
  const key = `${keyPrefix}:${req.ip}`;
  const script = `
  local key = KEYS[1]
  local limit = tonumber(ARGV[1])
  local window = tonumber(ARGV[2])
  local current = redis.call('INCR', key)
  if current == 1 then
    redis.call('EXPIRE', key, window)
  end
  return current
  `;
  try {
    const count = await redis.eval(script, 1, key, limit, window);
    if (count > limit) return res.status(429).send('Too Many Requests');
    next();
  } catch (e) {
    console.error('Rate limiter error', e);
    next(); // fail open
  }
};
```

### Distributed Locks (Redlock)

```bash
npm install redlock
```

```javascript
const Redlock = require('redlock');
const redlock = new Redlock([redis], {
  driftFactor: 0.01, // clock drift
  retryCount: 10,
  retryDelay: 200,
  retryJitter: 200
});

async function withLock(resource, ttl, fn) {
  const lock = await redlock.acquire([resource], ttl);
  try {
    return await fn();
  } finally {
    await lock.release();
  }
}

await withLock('locks:order:o-123', 5000, async () => {
  // critical section
});
```

---

## Resilience & Tuning

```javascript
const redis = new Redis({
  host: '127.0.0.1',
  port: 6379,
  maxRetriesPerRequest: 3,
  enableReadyCheck: true,
  retryStrategy: (times) => Math.min(times * 50, 2000), // backoff
  reconnectOnError: (err) => !!String(err).match(/READONLY|ETIMEDOUT/),
  enableOfflineQueue: true, // buffer while reconnecting
  keepAlive: 30000
});
```

- Use `pipeline` for batching to reduce RTT.
- Prefer `multi` for atomic updates.
- Set TTL for cache keys.
- Use hash tags `{...}` in cluster for multi-key ops.

---

## Monitoring

```javascript
const info = await redis.info('memory');
console.log(info);

const latency = await redis.latency('LATEST');
```

---

## Summary

- ioredis supports single, Sentinel, and Cluster setups.
- Implement caching, rate limiting, locks, Pub/Sub, Streams.
- Use pipelines and Lua for performance and atomicity.
- Add TTLs, backoff, and monitoring in production.

---

## Interview Questions & Answers

1) Q: Why choose ioredis over node-redis?
   A: ioredis offers built-in Cluster and Sentinel support, robust reconnection/backoff, pipelines, and better high-availability features out-of-the-box.

2) Q: How do you implement Cache-Aside in Node.js?
   A: Read cache → on miss load DB → set with TTL → return. See `cacheAside(key, ttl, loader)` helper.

3) Q: When use pipeline vs MULTI/EXEC?
   A: Pipeline batches commands to reduce round-trips (not atomic). MULTI/EXEC ensures atomicity for related updates.

4) Q: How to rate limit per IP?
   A: Use an atomic Lua script to INCR a key with EXPIRE window and compare with limit. Integrate as Express middleware.

5) Q: How to implement distributed locks?
   A: Use Redlock algorithm via `redlock` lib: acquire lock with TTL, run critical section, release lock, with retries and jitter.

6) Q: What is `scaleReads` in Cluster?
   A: ioredis can route reads to replicas (`'slave'`) to offload masters. Ensure eventual consistency is acceptable.

7) Q: How do consumer groups work with Streams?
   A: Create group, consumers `XREADGROUP` with `>` to claim new messages, `XACK` after processing, handle pending entries for retries.

8) Q: How to ensure multi-key ops in Cluster?
   A: Use hash tags `{tag}` in keys, e.g., `user:{1001}:name` and `user:{1001}:email` so both hash to same slot.

9) Q: What happens if Redis is down?
   A: Use `enableOfflineQueue` to buffer, add DB fallbacks, log errors, degrade gracefully; the app should continue where possible.

10) Q: How to avoid cache stampede?
    A: Locking (Redlock or SET NX), early refresh, soft expiration patterns. Serve stale data while refreshing.

11) Q: Why set TTL on cache keys?
    A: Prevent stale data and memory bloat; acts as safety net when invalidation fails.

12) Q: How to tune reconnection?
    A: `retryStrategy` for exponential backoff, `maxRetriesPerRequest`, `enableReadyCheck`, and `reconnectOnError` for specific errors.

13) Q: How to store JSON efficiently?
    A: Serialize with `JSON.stringify`, consider compression for large payloads, or store as hashes for field-level updates.

14) Q: How to implement a queue?
    A: Use `LPUSH` + `BRPOP` for simple FIFO, or Streams with consumer groups for durable, multi-consumer processing.

15) Q: Difference between Pub/Sub and Streams?
    A: Pub/Sub is ephemeral broadcast (no persistence, no replay). Streams persist events, support consumer groups, replay and backpressure.
